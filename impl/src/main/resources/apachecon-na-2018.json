{
  "okay": true,
  "rooms": [
    {
      "id": "c8647968fbca8348a",
      "name": "Track5",
      "days": [
        {
          "day": 1538092800,
          "slots": [
            {
              "starttime": 1538125200,
              "origin": "c8647968fbca8348a",
              "id": "5d9f51d56446a9d75",
              "duration": 50,
              "readonly": false,
              "request_id": "5d9f51d56446a9d75",
              "room": "c8647968fbca8348a",
              "day": 1538092800,
              "title": null,
              "endtime": 1538128200
            },
            {
              "starttime": 1538128800,
              "origin": "c8647968fbca8348a",
              "id": "b08ccfb1a1529b737",
              "duration": 50,
              "readonly": false,
              "request_id": "b08ccfb1a1529b737",
              "room": "c8647968fbca8348a",
              "day": 1538092800,
              "title": null,
              "endtime": 1538131800
            },
            {
              "starttime": 1538133600,
              "origin": "c8647968fbca8348a",
              "id": "ab776baee11b1f93e",
              "duration": 50,
              "readonly": false,
              "request_id": "ab776baee11b1f93e",
              "room": "c8647968fbca8348a",
              "day": 1538092800,
              "title": null,
              "endtime": 1538136600
            },
            {
              "starttime": 1538137200,
              "origin": "c8647968fbca8348a",
              "id": "c9aad6dfe7becee76",
              "duration": 50,
              "readonly": false,
              "request_id": "c9aad6dfe7becee76",
              "room": "c8647968fbca8348a",
              "day": 1538092800,
              "title": null,
              "endtime": 1538140200
            },
            {
              "starttime": 1538145600,
              "origin": "c8647968fbca8348a",
              "id": "2a46a68b26543eb0c",
              "duration": 50,
              "readonly": false,
              "request_id": "2a46a68b26543eb0c",
              "room": "c8647968fbca8348a",
              "day": 1538092800,
              "title": null,
              "endtime": 1538148600
            },
            {
              "starttime": 1538149200,
              "origin": "c8647968fbca8348a",
              "id": "2507db24560992b5d",
              "duration": 50,
              "readonly": false,
              "request_id": "2507db24560992b5d",
              "room": "c8647968fbca8348a",
              "day": 1538092800,
              "title": null,
              "endtime": 1538152200
            },
            {
              "starttime": 1538152800,
              "origin": "c8647968fbca8348a",
              "id": "e5fcfa2d2a8be0579",
              "duration": 50,
              "readonly": false,
              "request_id": "e5fcfa2d2a8be0579",
              "room": "c8647968fbca8348a",
              "day": 1538092800,
              "title": null,
              "endtime": 1538155800
            }
          ]
        },
        {
          "day": 1537920000,
          "slots": [
            {
              "starttime": 1537959900,
              "origin": "c8647968fbca8348a",
              "id": "fdbaff37edfcc22bd",
              "duration": 50,
              "readonly": false,
              "request_id": "fdbaff37edfcc22bd",
              "talk": {
                "created": 1522330712,
                "notes": "",
                "description": "Testing is an important process to assure quality in computer systems. Tests can be executed throughout the development process to detect early on coding problems. It is also a common practice to execute a more comprehensive set of tests when a version is prepared to be released.  However, there are still people that consider test cases a burden for the development process. This talk discusses testing methods for projects with legacy code, and how they can shape code and improve productivity. We will differentiate two different test methods, and use Apache CloudStack (ACS) context as a use case.",
                "tags": "",
                "id": "b7c6f66c44571926c",
                "pending": false,
                "bio": "Rafael Weingärtner is a PMC and Committer for Apache CloudStack. He has over three (5) years of experience creating and maintaining cloud computing environments orchestrated by Apache CloudStack. In his free time, Rafael executes the refactorings and cleanups in CloudStack’s large code base.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "b7c6f66c44571926c",
                "onhold": false,
                "title": "Community culture, code quality and testability.",
                "speaker": "Rafael Weingärtner",
                "conference": "apachecon-north-america-2018",
                "submitter": "4db65f38114c8562d46bc03c3a913dd999d6b9d4",
                "level": 1,
                "accepted": true
              },
              "room": "c8647968fbca8348a",
              "day": 1537920000,
              "assignee": "b7c6f66c44571926c",
              "title": null,
              "endtime": 1537962900
            },
            {
              "starttime": 1537963500,
              "origin": "c8647968fbca8348a",
              "id": "3709a32cb5b64ece9",
              "duration": 50,
              "readonly": false,
              "request_id": "3709a32cb5b64ece9",
              "talk": {
                "created": 1522278013,
                "notes": "",
                "description": "How our cloud works. Full automation with Ansible for all infrastructure components of our cloud with CloudStack, check_mk, LDAP and more. All functionality is available through a customer portal. The setup is fully scalable for larger landscapes.",
                "tags": "CloudStack",
                "id": "6f90dbda7b9214aaf",
                "pending": false,
                "bio": "Ingo Jochim has worked for itelligence as Senior Architect in Dresden since 2010, focusing on implementation and automation of large cloud environments. Ingo has more than 15 years experience in data center operations and likes Enduro off-road races.\nAndre Walter leads the Cloud Infrastructure Services area. He is an expert in operations of large infrastructure landscapes. Andre likes running Marathons.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "6f90dbda7b9214aaf",
                "onhold": false,
                "title": "CloudStack with Ansible Automation",
                "speaker": "Ingo Jochim, Andre Walter",
                "conference": "apachecon-north-america-2018",
                "submitter": "51b3da56c42de192abf4652da0cafedada7ed0ac",
                "level": 1,
                "accepted": true
              },
              "room": "c8647968fbca8348a",
              "day": 1537920000,
              "assignee": "6f90dbda7b9214aaf",
              "title": null,
              "endtime": 1537966500
            },
            {
              "starttime": 1537972200,
              "origin": "c8647968fbca8348a",
              "id": "be140072b4e83a7e0",
              "duration": 50,
              "readonly": false,
              "request_id": "be140072b4e83a7e0",
              "talk": {
                "created": 1521639797,
                "notes": "No special requirements - standard presentation requiring projector and wifi only.",
                "description": "The CloudStack usage service is used to track consumption of resources in Apache CloudStack for reporting and billing purposes.\nThis talk will give an overview of how the service is installed and configured, before diving deeper into how data is processed from the CloudStack database into the different usage types (VMs, network usage, storage, etc.), before being aggregated into billable units or time slices in the usage database. The talk will include a number of examples on how to query and report on this usage data, and also look at general maintenance and troubleshooting of the service.\nTarget audience: CloudStack operators looking to improve reporting and billing on consumed resources. ",
                "tags": "cloudstack,usage,metrics,billing",
                "id": "35c6c7a3d9b78386d",
                "pending": false,
                "bio": "Dag Sonstebo is a Cloud Architect at ShapeBlue, the leading global independent integrator of Cloudstack technologies and specialists in consultancy, design and implementation of IaaS cloud infrastructure. Dag has 20 years experience as a technical architect and engineer in the service provider, financial and manufacturing industries and has a great interest in everything cloud, virtualisation and automation. He is currently working with a number of Service Providers developing their IaaS cloud infrastructure. In his spare time Dag rides motorbikes, plays guitar and likes travelling. Dag has in the past presented talks at ApacheCon, CloudStack Collaboration Conferences as well as a number of other CloudStack and Virtualisation meetups and user groups.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "onhold": false,
                "request_id": "35c6c7a3d9b78386d",
                "title": "[CloudStack]:CloudStack usage service deep dive",
                "speaker": "Dag Sonstebo",
                "conference": "apachecon-north-america-2018",
                "submitter": "991906e74de30774c29c3107f1fef2727b2ca8a6",
                "level": 0,
                "accepted": true
              },
              "room": "c8647968fbca8348a",
              "day": 1537920000,
              "assignee": "35c6c7a3d9b78386d",
              "title": null,
              "endtime": 1537975200
            },
            {
              "starttime": 1537975800,
              "origin": "c8647968fbca8348a",
              "id": "598babed4c3b2c0a5",
              "duration": 50,
              "readonly": false,
              "request_id": "598babed4c3b2c0a5",
              "talk": {
                "created": 1522072662,
                "notes": "",
                "description": "This session will cover all Billing challenges for a Cloud Service Providers (CSP) using Apache CloudStack. \nTenants on-boarding workflows, storefront, subscription management, rating, billing, payment and white label reseller management in a CloudStack context will be addressed.  \nSeveral CSPs case studies and demonstrations of Amysta Billing will be part of this session\n",
                "tags": "Billing",
                "id": "8681fc851b6219977",
                "pending": false,
                "bio": "Pierre Vacherand is the CTO of Apalia, a System integrator specialized in Open Cloud. Pierre is a Cloud IaaS specialist and has been involved with CloudStack since 2010. He led the design of Amysta, a Cloud Management Platform supporting CloudStack. Pierre has been speaking at “Build a Cloud Days”, CloudStack meetups and several CloudStack Collaboration Conference Europe & US ",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "8681fc851b6219977",
                "onhold": false,
                "title": "Billing for Apache CloudStack",
                "speaker": "Pierre VACHERAND",
                "conference": "apachecon-north-america-2018",
                "submitter": "5c561fa7780eb79307eb2c250b08a94f501e73cf",
                "level": 0,
                "accepted": true
              },
              "room": "c8647968fbca8348a",
              "day": 1537920000,
              "assignee": "8681fc851b6219977",
              "title": null,
              "endtime": 1537978800
            },
            {
              "starttime": 1537980000,
              "origin": "c8647968fbca8348a",
              "id": "793a7845e6f972d90",
              "duration": 50,
              "readonly": false,
              "request_id": "793a7845e6f972d90",
              "talk": {
                "created": 1522431200,
                "notes": "HDMI projector would be great. VGA works fine too.",
                "description": "This talk is for CloudStack administrators who're responsible for maintaining a robust and fault-free production deployment. It covers monitoring fine grained parameters of a CloudStack installation and how to measure and check not just discrete values but also routinely performed actions against their expected outcome. It also dwells upon how the same discrete values make a difference from an access perspective. Whether you want to auto-resolve common problems, provide an SLA or just keep a tab on your deployment, this talk will definitely provide some insights.",
                "tags": "CloudStack Users, Monitoring",
                "id": "e5b123e6ed01f2ec2",
                "pending": false,
                "bio": "Shiv is Co-Founder and CTO of IndiQus Technologies Pvt. Ltd. and a CloudStack user turned evangelist since 2013. He loves tinkering on CloudStack and the possibilities it offers. He has deployed multiple public and private clouds running CloudStack in the South Asian region and has also integrated legacy systems with CloudStack. He would love to share his experiences with like minded professionals.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "e5b123e6ed01f2ec2",
                "onhold": false,
                "title": "CloudStack Monitoring - In-Depth Checks For Production Deployments",
                "speaker": "K B Shiv Kumar",
                "conference": "apachecon-north-america-2018",
                "submitter": "9015c053476ebc5bf5936adf9b32225dc7b8951d",
                "level": 1,
                "accepted": true
              },
              "room": "c8647968fbca8348a",
              "day": 1537920000,
              "assignee": "e5b123e6ed01f2ec2",
              "title": null,
              "endtime": 1537983000
            }
          ]
        },
        {
          "day": 1537833600,
          "slots": [
            {
              "starttime": 1537866000,
              "origin": "c8647968fbca8348a",
              "id": "c53085ca86cc07e9f",
              "duration": 50,
              "readonly": false,
              "request_id": "c53085ca86cc07e9f",
              "room": "c8647968fbca8348a",
              "day": 1537833600,
              "assignee": null,
              "title": null,
              "endtime": 1537869000
            },
            {
              "starttime": 1537869600,
              "origin": "c8647968fbca8348a",
              "id": "bf9ea4e1b9cf7adba",
              "duration": 50,
              "readonly": false,
              "request_id": "bf9ea4e1b9cf7adba",
              "talk": {
                "created": 1522362393,
                "notes": "Projector, Clicker, Laser Pointer",
                "description": "Imagine migrating 1,200 hosts and 16,000 VMs from Xen to KVM, all while maintaining existing networking and integration functionality and providing a seamless transition for the infrastructure users.  This is exactly what TicketMaster has taken on with the support of CloudOps as they adopt Apache CloudStack as their virtualization orchestrator.  Learn about the challenges faced and the creative solutions developed to enable the successful transition.",
                "tags": "CloudStack",
                "id": "888a871e52b0af840",
                "pending": false,
                "bio": "At Ticketmaster, Jean-Francois Nadeau is a senior systems engineer with a focus on open source solutions.  With a large ecosystem of teams consuming their infrastructure, they focus on technologies which are flexible while also being operationally efficient.\n\nAt Cloudops, Syed Ahmed is a software developer focusing on integrations and hard to solve problems.  With extensive knowledge throughout the hardware and software stack, he is able to add a unique perspective to solving integration and orchestration challenges.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "888a871e52b0af840",
                "onhold": false,
                "title": "A Journey to CloudStack",
                "speaker": "Jean-Francois Nadeau, Syed Ahmed",
                "conference": "apachecon-north-america-2018",
                "submitter": "f0b3e9caa644f71668a36542480169077056ad3d",
                "level": 1,
                "accepted": true
              },
              "room": "c8647968fbca8348a",
              "day": 1537833600,
              "assignee": "888a871e52b0af840",
              "title": null,
              "endtime": 1537872600
            },
            {
              "starttime": 1537874400,
              "origin": "c8647968fbca8348a",
              "id": "66977f5a22b7b2e28",
              "duration": 50,
              "readonly": false,
              "request_id": "66977f5a22b7b2e28",
              "talk": {
                "created": 1522345107,
                "notes": "might be more a ~30mins talk, should be attached to the cloudstack collab.",
                "description": "Brief how to on collecting metrics, events and logs from Cloudstack. How we are planning to improve centralization of those precious data in CloudStack code. prensent example of troubleshooting help they provide and system visility.",
                "tags": "cloudstack",
                "id": "8c87deb87e0d8b139",
                "pending": false,
                "bio": "Working on cloud.ca since 2012, Apache CloudStack PMC member, held various roles in web operations and now on a cloud architecture role.\nCloud infrastructure and automation antousiast,\nDevOps fan, meetup organizer and metric collection maniac.\n",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "8c87deb87e0d8b139",
                "onhold": false,
                "title": "logs and metric collection in Apache CloudStack",
                "speaker": "Pierre-Luc Dion",
                "conference": "apachecon-north-america-2018",
                "submitter": "985e6d9a7234787ce6a067ff606266c1da5a03c3",
                "level": 1,
                "accepted": true
              },
              "room": "c8647968fbca8348a",
              "day": 1537833600,
              "assignee": "8c87deb87e0d8b139",
              "title": null,
              "endtime": 1537877400
            },
            {
              "starttime": 1537878000,
              "origin": "c8647968fbca8348a",
              "id": "c7b56de35473eb229",
              "duration": 50,
              "readonly": false,
              "request_id": "c7b56de35473eb229",
              "talk": {
                "created": 1522275282,
                "notes": "",
                "description": "Apache CloudStack has been called in previous ApacheCon CCC sessions as the dark matter in the universe; it is definitely there, only not always shiny. In the belief that many CloudStack deployments are out there and many would be legacy technology based like e.g. deploying linux bridges for networking, at Nuage Networks we invested in API support to assist in the migration (or transforming) of guest networks from one physical network to another while preserving their deployed workloads. The team successfully integrated this work into ACS 4.11. The presentation will provide the technical overview of how that is realized and showcase an orchestrated migration from linux bridging to Nuage Networks SDN in a deployed Apache CloudStack cloud.",
                "tags": "",
                "id": "4501094783f32a07a",
                "pending": false,
                "bio": "Kris Sterckx is the CloudStack development lead within Nuage Networks from Nokia. Kris lives and works in Antwerp, Belgium.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "4501094783f32a07a",
                "onhold": false,
                "title": "CloudStack : Migrating\/Transforming your guest networks in Apache CloudStack",
                "speaker": "Kris Sterckx",
                "conference": "apachecon-north-america-2018",
                "submitter": "56682c71f813ee60d1fc2145a2aa7c9aa20a7b07",
                "level": 1,
                "accepted": true
              },
              "room": "c8647968fbca8348a",
              "day": 1537833600,
              "assignee": "4501094783f32a07a",
              "title": null,
              "endtime": 1537881000
            },
            {
              "starttime": 1537886400,
              "origin": "c8647968fbca8348a",
              "id": "e32964071cb6f3471",
              "duration": 50,
              "readonly": false,
              "request_id": "e32964071cb6f3471",
              "talk": {
                "created": 1522400280,
                "notes": "",
                "description": "In this talk, StorPool will present its integration with CloudStack. Where it plugs; how easy (or hard) it was to do; its features; its roadmap; how it is used and what's special about it.\n\nIn the first half of the talk, we'll focus on development and CloudStack internals. During the second half, we'll cover topics concerning using CloudStack with the new integration.\n\nCome and see lessons learned while building our CloudStack integration!",
                "tags": "cloudstack, integration",
                "id": "5f0f9440e4e74b84f",
                "pending": false,
                "bio": "Mr. Boyan Krosnov is a Co-Founder and Chief Product Officer of StorPool Storage. He is in charge of the solution architecture, helping cloud operators build and maintain all aspects of their public and private clouds.\n\nHe has been part of the technical teams building 5 service providers from scratch in 4 countries. In most of these projects, he has designed the architecture, led the technical teams and managed the implementation of projects in the millions. He is also a co-founder of ultra-high performance networking software company PacketScale, processing millions of packets per second on standard x86 servers.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "5f0f9440e4e74b84f",
                "onhold": false,
                "title": " The story of building our CloudStack storage integration",
                "speaker": "Boyan Krosnov",
                "conference": "apachecon-north-america-2018",
                "submitter": "d28c5dc27a1eeafbc57671777849d82732fecf39",
                "level": 1,
                "accepted": true
              },
              "room": "c8647968fbca8348a",
              "day": 1537833600,
              "assignee": "5f0f9440e4e74b84f",
              "title": null,
              "endtime": 1537889400
            },
            {
              "starttime": 1537890000,
              "origin": "c8647968fbca8348a",
              "id": "eb90f945eec0c7bfc",
              "duration": 50,
              "readonly": false,
              "request_id": "eb90f945eec0c7bfc",
              "talk": {
                "created": 1522246132,
                "notes": "",
                "description": "This is about our way from NFS to CEPH as primary Storage in CloudStack. Disadvantages about NFS as primary Storage - recommendations for CEPH - what can go wrong. Stories of a Sysadmin.",
                "tags": "CloudStack",
                "id": "d3b061c4a120801e8",
                "pending": false,
                "bio": "Sebastian Bretschneider\nCloud Architect\nworking at itelligence Global Managed Services in Germany\nSebastian is a Certified Apache CloudStack Expert. He loves to automate infrastructure components using Ansible automation.\nCeph is a core technology he likes to work with in cloud environments.\nSebastian likes to ride on two wheels, motocycle and bicycle.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "d3b061c4a120801e8",
                "onhold": false,
                "title": "CloudStack + Ceph",
                "speaker": "S. Bretschneider",
                "conference": "apachecon-north-america-2018",
                "submitter": "d0973943db03c483b9dedb6c3f829352798bc4da",
                "level": 1,
                "accepted": true
              },
              "room": "c8647968fbca8348a",
              "day": 1537833600,
              "assignee": "d3b061c4a120801e8",
              "title": null,
              "endtime": 1537893000
            },
            {
              "starttime": 1537893600,
              "origin": "c8647968fbca8348a",
              "id": "c41fdafb09cdf4c98",
              "duration": 50,
              "readonly": false,
              "request_id": "c41fdafb09cdf4c98",
              "talk": {
                "created": 1522313556,
                "notes": "",
                "description": "In this talk you will see wich tools we use to generate billing reports for cloudstack and what were the difficulties which we discovered during the implementation.",
                "tags": "Cloudstack",
                "id": "dcf32b078a6d4f21d",
                "pending": false,
                "bio": "Alexander works for a project at itelligence where  technologies like cloudstack and ceph are used.\nHis main task area is to take care of the landscapewide monitoring and the implementation of the billing system.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "onhold": false,
                "request_id": "dcf32b078a6d4f21d",
                "title": "Billing with CloudStack",
                "speaker": "Alexander Stock",
                "conference": "apachecon-north-america-2018",
                "submitter": "3994142aa459ab36150df57430098f9cb396e4d1",
                "level": 1,
                "accepted": true
              },
              "room": "c8647968fbca8348a",
              "day": 1537833600,
              "assignee": "dcf32b078a6d4f21d",
              "title": null,
              "endtime": 1537896600
            },
            {
              "starttime": 1537896300,
              "origin": "c8647968fbca8348a",
              "id": "880b33f8d5fdd94ef",
              "duration": 50,
              "readonly": false,
              "request_id": "880b33f8d5fdd94ef",
              "talk": {
                "created": 1522426044,
                "notes": "",
                "description": "You can build a useful two node CloudStack for less than $500 shipped. What hardware I ordered. How I picked the hardware. And ways to get the most for you money. What I learned while setting up CloudStack, including the mistakes I made you can learn from. The purpose I have used my cloud for. How that matched my expectation, and the ways it did not. Start small you can always upgrade later.",
                "tags": "cloudstack",
                "id": "ed119c819c39bb5d4",
                "pending": false,
                "bio": "I’m a husband and Dad. Home sysadmin and computer programmer with 20+ years for professional experience. I’ve always tried to make installation and software deployment better, long before devops was called devops. Writing Java, C\/C++, python, ansible, or whatever the contract requires.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "ed119c819c39bb5d4",
                "onhold": false,
                "title": "Your Own CloudStack for less than $500",
                "speaker": "Darren Cole",
                "conference": "apachecon-north-america-2018",
                "submitter": "d584163841b33e74c067482285551914f1d325cc",
                "level": 1,
                "accepted": true
              },
              "room": "c8647968fbca8348a",
              "day": 1537833600,
              "assignee": "ed119c819c39bb5d4",
              "title": null,
              "endtime": 1537899300
            }
          ]
        },
        {
          "day": 1538006400,
          "slots": {}
        }
      ]
    },
    {
      "id": "6f2a4d4b2751e7f8f",
      "name": "Track1",
      "days": [
        {
          "day": 1538006400,
          "slots": [
            {
              "starttime": 1538043300,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "6d8aa8300b9b93ff0",
              "duration": 50,
              "readonly": false,
              "request_id": "6d8aa8300b9b93ff0",
              "talk": {
                "created": 1522354380,
                "notes": "",
                "description": "Deep learning is so popular, and Tensorflow is one of the most popular deep learning platforms. More and more enterprises start trying Tensorflow to solve their use cases. Putting Tensorflow into production is hard. Especially for distribute Tensorflow, which may need to answer questions like:\n- How to choose machine configurations, GPUs, etc.?\n- How many parameter servers needed?\n- How to do parallel hyperparameter tuning?\n- How to choose Docker v.s. non-docker?\n- How to do container placement for better performance?\n- How to efficiently work with other big data applications like Hive\/Spark, etc.?\n- How to do resource reservation for predictability? \nWith latest features added to YARN, such as GPU isolation, placement constraints (how to wisely place workers\/parameter servers to better leverage resources), docker container integration, native service support, etc. Now there're lots of works can be done within YARN to better support deep learning and machine learning workloads.\nIn this talk, we will talk about challenges of running Tensorflow in a production environment, and how to use Apache Hadoop YARN 3.0 to solve these issues.",
                "tags": "TensorFlow, Hadoop, Spark, Deep Learning",
                "id": "2d4a1d65da8db09e7",
                "pending": false,
                "bio": "Wangda Tan is Product Management Committee (PMC) member of Apache Hadoop and Staff Software Engineer at Hortonworks. His major working field is Hadoop YARN GPU isolation and resource scheduler, participated features like node labeling, resource preemption, container resizing etc. Before join Hortonworks, he was working at Pivotal, working on integration OpenMPI\/GraphLab with Hadoop YARN. Before that, he was working at Alibaba cloud computing, participated creating a large scale machine learning, matrix and statistics computation platform using Map-Reduce and MPI.\n\nYanbo is a staff software engineer at Hortonworks. His main interests center around implementing effective machine learning and deep learning algorithms or models in the areas of recommendation system, natural language processing and others. He is an Apache Spark PMC member and contributes to lots of other open source projects such as TensorFlow and Apache MXNet. He delivered the implementation of some core Spark MLlib algorithms. Prior to Hortonworks, he was a software engineer at Yahoo! and France Telecom working on machine learning and distributed system.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "2d4a1d65da8db09e7",
                "onhold": false,
                "title": "Running distributed TensorFlow in production: challenges and solutions on YARN 3.0",
                "speaker": "Wangda Tan, Yanbo Liang",
                "conference": "apachecon-north-america-2018",
                "submitter": "7f43f4609211233e6b890b95525c536bbfc2dbcf",
                "level": 1,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1538006400,
              "assignee": "2d4a1d65da8db09e7",
              "title": null,
              "endtime": 1538046300
            },
            {
              "starttime": 1538046900,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "9391b42349a8a23eb",
              "duration": 50,
              "readonly": false,
              "request_id": "9391b42349a8a23eb",
              "talk": {
                "created": 1522294429,
                "notes": "",
                "description": "Stories about personal data being harvested and abused by corporations have been all over the news in 2018.  Thousands of companies worldwide have recently taken steps to comply with the EU's GPDR law.  The law includes a requirements that companies allow EU citizens to discover what information is being maintained about them, the purposes to which that information is being put, and download a copy.  Many companies have found it easier to make these capabilities available to anyone than attempt to limit them based on the citizenship of each consumer.\n\nApache Streams unifies a diverse world of digital profiles and online activities into common formats and vocabularies, and makes these datasets accessible across a variety of databases, devices, and platforms for streaming, browsing, search, sharing, and analytics use-cases.  New capabilities have been added this year that can process the export archives of popular web platform, converting them into structured data based on the Activity Streams specification.  This talk will demonstrate how to bulk export your profile, post, and connection details from prominent social networks,  use Apache Streams to process them into structured data, and load them into databases you control.",
                "tags": "data,streams,internal,java,privacy",
                "id": "0eca59eeb832b40bb",
                "pending": false,
                "bio": "Steve is VP of Technology at People Pattern, PMC Chair of Apache Streams, and PMC Member of Apache Juneau and the Apache Incubator.  Many of his on-going and recent projects involve(d) gathering and integrating disparate online data sources to support applications and predictive models.\n\nhttp:\/\/people.apache.org\/~sblackmon\/#\/",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "0eca59eeb832b40bb",
                "onhold": false,
                "title": "Personal Data Portability using Apache Streams",
                "speaker": "Steve Blackmon",
                "conference": "apachecon-north-america-2018",
                "submitter": "42785e1f1a3a4cb98b27824c7ff64be9122f645b",
                "level": 0,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1538006400,
              "assignee": "0eca59eeb832b40bb",
              "title": null,
              "endtime": 1538049900
            },
            {
              "starttime": 1538050500,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "64293395ccf3f002e",
              "duration": 50,
              "readonly": false,
              "request_id": "64293395ccf3f002e",
              "talk": {
                "created": 1522252853,
                "notes": "",
                "description": "YARN is predominantly utilised for Big data workload by enterprise customers and for other workloads they had to look out for different schedulers like Mesos and Kubernetes. Hence there was a pressing need to address the requirement gaps existing for other workloads. In this talk i would detail about the new YARN features as part of HADOOP 3.1 and other upcoming features which makes it favourable for all kinds of workloads to be deployed on top of YARN.",
                "tags": "YARN,HADOOP, SCHEDULING, BIG DATA, LONG LIVED SERVICES, ",
                "id": "7fa8a9a9a664ad524",
                "pending": false,
                "bio": "I am active contributor to Hadoop community and thus in the process have become Committer and PMC of HADOOP. At same time i would like to understand and speak about distributed scheduling landscape.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "7fa8a9a9a664ad524",
                "onhold": false,
                "title": "YARN 3.1 and Beyond",
                "speaker": "Naganarasimha",
                "conference": "apachecon-north-america-2018",
                "submitter": "d09bc629b9efeb1951358a700d81fdb4e1c10c55",
                "level": 1,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1538006400,
              "assignee": "7fa8a9a9a664ad524",
              "title": null,
              "endtime": 1538053500
            },
            {
              "starttime": 1538058600,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "45aea44411dbbe220",
              "duration": 50,
              "readonly": false,
              "request_id": "45aea44411dbbe220",
              "talk": {
                "created": 1522251227,
                "notes": "",
                "description": "Deep learning is useful for enterprises tasks in the field of speech recognition, image classification, AI chatbots and machine translation, just to name a few.\n\nIn order to train deep learning\/machine learning models, applications such as TensorFlow \/ MXNet \/ Caffe \/ XGBoost can be leveraged. And sometimes these applications will be used together to solve different problems. \n\nTo make distributed deep learning\/machine learning applications easily launched, managed, monitored, we introduced, in Apache Hadoop 3.x, YARN native services along with other improvements such as first-class GPU support, container-DNS support, scheduling improvements, etc. These improvements make distributed deep learning\/machine learning applications run on YARN as simple as running it locally, which can let machine-learning engineers focus on algorithms instead of worrying about underlying infrastructure. Also, YARN can better manage a shared cluster which runs deep learning\/machine learning and other services\/ETL jobs with these improvements.\n\nIn this session, we will take a closer look at these improvements and show how to run these applications on YARN with demos. Audiences can start trying running these applications on YARN after this talk.",
                "tags": "",
                "id": "a2bc02b2eb2c1fe2e",
                "pending": false,
                "bio": "Wangda Tan is Product Management Committee (PMC) member of Apache Hadoop and Staff Software Engineer at Hortonworks. His major working field is Hadoop YARN GPU isolation and resource scheduler, participated features like node labeling, resource preemption, container resizing etc. Before join Hortonworks, he was working at Pivotal, working on integration OpenMPI\/GraphLab with Hadoop YARN. Before that, he was working at Alibaba cloud computing, participated creating a large scale machine learning, matrix and statistics computation platform using Map-Reduce and MPI.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "a2bc02b2eb2c1fe2e",
                "onhold": false,
                "title": "Deep learning on YARN - Running distributed Tensorflow \/ MXNet \/ Caffe \/ XGBoost on Hadoop clusters",
                "speaker": "Wangda Tan",
                "conference": "apachecon-north-america-2018",
                "submitter": "39fb2a644cc34939291f2713d1632586da3e4206",
                "level": 1,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1538006400,
              "assignee": "a2bc02b2eb2c1fe2e",
              "title": null,
              "endtime": 1538061600
            },
            {
              "starttime": 1538062200,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "61e1afece2e8ede05",
              "duration": 50,
              "readonly": false,
              "request_id": "61e1afece2e8ede05",
              "talk": {
                "created": 1522426748,
                "notes": "",
                "description": "Fine-grained data protection at a column level in data lake environments has become a mandatory requirement to demonstrate compliance with multiple local and international regulations across many industries today. ORC is a self-describing type-aware columnar file format designed for Hadoop workloads that provides optimized streaming reads, but with integrated support for finding required rows quickly. In this talk, we will outline the progress made in Apache community for adding fine-grained column level encryption natively into ORC format that will also provide capabilities to mask or redact data on write while protecting sensitive column metadata such as statistics to avoid information leakage. The column encryption capabilities will be fully compatible with Hadoop Key Management Server (KMS) and use the KMS to manage master keys providing the additional flexibility to use and manage keys per column centrally. An end to end scenario that demonstrates how this capability can be leveraged will be also demonstrated.",
                "tags": "ORC,Encryption,privacy,security",
                "id": "49b76693e9b1f4e20",
                "pending": false,
                "bio": "Owen O'Malley is a co-founder and technical fellow at Hortonworks, a rapidly growing company (25 to 1,000 employees in 5 years), which develops the completely open source Hortonworks Data Platform (HDP). HDP includes Hadoop and the large ecosystem of big data tools that enterprises need for their data analytics. Owen has been working on Hadoop since the beginning of 2006 at Yahoo, was the first committer added to the project, and used Hadoop to set the Gray sort benchmark in 2008 and 2009. In the last 8 years, he has been the architect of MapReduce, Security, and now Hive. Recently he has been driving the development of the ORC file format and adding ACID transactions to Hive. Before working on Hadoop, he worked on Yahoo Search's WebMap project, which was the original motivation for Yahoo to work on Hadoop.  Prior to Yahoo, he wandered between testing (UCI), static analysis (Reasoning), configuration management (Sun), and software model checking (NASA). He received his PhD in Software Engineering from University of California, Irvine.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "49b76693e9b1f4e20",
                "onhold": false,
                "title": "Enciphering the ORC: Fine-Grained Column Level Encryption for your Hadoop Data Lakes",
                "speaker": "Owen O'Malley",
                "conference": "apachecon-north-america-2018",
                "submitter": "e7b01827de0840cce2b4a8473d701442927ae020",
                "level": 1,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1538006400,
              "assignee": "49b76693e9b1f4e20",
              "title": null,
              "endtime": 1538065200
            },
            {
              "starttime": 1538065800,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "e9d0a50fcfcc47f16",
              "duration": 50,
              "readonly": false,
              "request_id": "e9d0a50fcfcc47f16",
              "talk": {
                "created": 1522376828,
                "notes": "",
                "description": "Apache HAWQ is Apache Hadoop native SQL engine that combines the key technological advantages of MPP database with the scalability and convenience of Hadoop. \n\nIt’s a big challenge to deploy a distributed database on Kubernetes. This talk presents the architecture and implementation details by integrating Apache HAWQ with Kubernetes natively. The key to this architecture is the HAWQ Operator that abstracts HAWQ cluster as a custom resource on Kubernetes and has related controllers to automate HAWQ cluster creation, management, upgrade, expansion, etc.\n\nBased on these technologies, multiple HAWQ clusters could be managed on Kubernetes easily. DBA and users don't need to care about any administration, scalability and availability stuff which are main pain points in the traditional distributed database environment.",
                "tags": "hawq, kubernetes, cloud, database, mpp",
                "id": "a0e9a3a1877a152ae",
                "pending": false,
                "bio": "Ivan Weng, iweng@pivotal.io, Principal Software Engineer at Pivotal, Apache HAWQ Committer, PMC member. Primary focus on distributed system, database kernel and cloud computing technical areas.\n\nLin Wen, wlin@pivotal.io, Staff Software Engineer at Pivotal. He is now living in Beijing. He contributes to Apache HAWQ project since 2015, including Kubernetes integration, fault tolerance, resource management, Ranger integration, etc. Before join Pivotal, he used to work for Oracle and VMware.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "a0e9a3a1877a152ae",
                "onhold": false,
                "title": "Apache HAWQ on Kubernetes: Bring SQL on Hadoop to Cloud",
                "speaker": "Ivan Weng, Wen Lin",
                "conference": "apachecon-north-america-2018",
                "submitter": "3025ff4e34497cde6c87eac1a16bd20dd153979a",
                "level": 1,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1538006400,
              "assignee": "a0e9a3a1877a152ae",
              "title": null,
              "endtime": 1538068800
            }
          ]
        },
        {
          "day": 1538092800,
          "slots": [
            {
              "starttime": 1538125200,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "1a82773075f475676",
              "duration": 50,
              "readonly": false,
              "request_id": "1a82773075f475676",
              "talk": {
                "created": 1522314990,
                "notes": "",
                "description": "Kubernetes slowly become one of the most popular container runtime environment while Hadoop has already been widely used open source bigdata  platform since a long time. The questions is here: how can we use the new cloud-native toolset to administer and manage Hadoop based clusters? Is there any benefit to run Hadoop and other bigdata application on top of Kubernetes?\n\nIn this presentation I will show that Hadoop is not a legacy application but it could be run very easy in cloud-native environment thanks to the generic and distributed by design.\n\nThe first step to run an application in a Kuberrnetes cluster is containerization. Creating containers for an application is easy (even if it’s a goold old distributed application like Apache Hadoop), just a few steps of packaging. The hard part isn't packaging: it's deploying\n\nHow can we run the containers together? How to configure them? How do the services in the containers find and talk to each other? How do you deploy and manage clusters with hundred of nodes?\n\nModern cloud native tools like Kubernetes or Consul\/Nomad could help a lot but they could be used in different way.\n\nIt this presentation I will demonstrate multiple solutions to manage containerized clusters with different cloud-native tools including kubernetes, and docker-swarm\/compose.\n\nNo matter which tools you use, the same questions of service discovery and configuration management arise. This talk will show the key elements needed to make that containerized cluster work.",
                "tags": "kubernetes, docker, consul, nomad",
                "id": "133a4d266ba653516",
                "pending": false,
                "bio": "Marton Elek has close to two decades of experience developing, architecting and implementing various type of software solutions. During this years he worked with almost all the form of Java application from low-latency modular application to big enterprise integration projects. But he believes that familiarity with multiple programming languages could help to find the best solution for a given problem, so he has also big interest in other functional and non-functional languages and different type of containerization techniques.  \n\nRecently he is working with Hadoop\/Spark based solutions as Lead Developer Engineer at Hortonworks. He is contributor in the Apache Ratis project which is a highly customizable Raft protocol implementation for Java projects. He is also contributor for the Hadoop project and worked on different type of containerization for Hadoop with tools like Docker, Docker Swarm, Nomad or Kubernetes.  \n\nHe is founder of the first Hungarian Java User Group and regular speaker on meetups and conferences.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "133a4d266ba653516",
                "onhold": false,
                "title": "From docker to kubernetes: running Apache Hadoop in a cloud native way",
                "speaker": "Marton Elek",
                "conference": "apachecon-north-america-2018",
                "submitter": "920d5559ea70a5185379c7663766484aa915f9f1",
                "level": 1,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1538092800,
              "assignee": "133a4d266ba653516",
              "title": null,
              "endtime": 1538128200
            },
            {
              "starttime": 1538128800,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "c687d3a0657e5d129",
              "duration": 50,
              "readonly": false,
              "request_id": "c687d3a0657e5d129",
              "talk": {
                "created": 1522384289,
                "notes": "",
                "description": "Industrial Big Data Analysis in Smart Factory requires real time processing for streaming data. SK Hynix as one of the world’s largest semiconductor factories gets the insight of the whole process as well as monitoring the factory like anomaly detection by processing the data in real time manner.\n\nIn this session, we will introduce an elastic data processing cloud service built on Apache Kafka and Druid in Kubernetes and present how to process the huge data from the smart semiconductor manufacturer in real time based on the workload. The cloud service can automatically scale up Druid cluster and scale it back down quickly to satisfy the aforementioned requirement with no latency despite of data collection and analytic workload.",
                "tags": "Streaming, Scalability, Druid, Kubernetes",
                "id": "23d24c61ed1db2d3a",
                "pending": false,
                "bio": "Jinchul Kim is a back-end software engineer with 12 years experience at databases and distributed systems. His focuses have been on query optimization, distributed data processing, scalable services and cloud computing systems. He currently works as a senior engineer for OLAP and MPP SQL engines development to accelerate telco. and semiconductor data analysis at SK Telecom. Before joining the current company, he worked at SAP as a SAP HANA engine developer for about 10 years.\n\nJuneWoo is a software engineer at databases and distributed computing system. His role is a data engineer for OLAP engine and cloud service development to accelerate semiconductor data analysis at SK Telecom. Before joining the current company, he worked at SAP HANA Core development and research for about 6 years.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "23d24c61ed1db2d3a",
                "onhold": false,
                "title": "Apache Druid on Kubernetes: Elastic scalable cloud-based system for real-time OLAP on high velocity data",
                "speaker": "Jinchul Kim, JuneWoo",
                "conference": "apachecon-north-america-2018",
                "submitter": "ba4915d724b43cc800f754a2a8deec56bb62b228",
                "level": 1,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1538092800,
              "assignee": "23d24c61ed1db2d3a",
              "title": null,
              "endtime": 1538131800
            },
            {
              "starttime": 1538133600,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "487c31c2eecf2abf7",
              "duration": 50,
              "readonly": false,
              "request_id": "487c31c2eecf2abf7",
              "talk": {
                "created": 1520479013,
                "notes": "",
                "description": "Your queries won't run fast if your data is not organized right. Apache Calcite optimizes queries, but can we make it optimize data? We had to solve several challenges. Users are too busy to tell us the structure of their database, and the query load changes daily, so Calcite has to learn and adapt. We talk about new algorithms we developed for gathering statistics on massive database, and how we infer and evolve the data model based on the queries.",
                "tags": "calcite,sql,business intelligence",
                "id": "d0866eb35bd85d3d9",
                "pending": false,
                "bio": "Julian Hyde is an expert in query optimization and in-memory analytics. He founded Apache Calcite, a framework for query optimization and data virtualization. He also founded Mondrian, the most popular open source OLAP engine. He is an architect at Looker.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "d0866eb35bd85d3d9",
                "onhold": false,
                "title": "Don’t optimize my queries, optimize my data!",
                "speaker": "Julian Hyde",
                "conference": "apachecon-north-america-2018",
                "submitter": "9e8f01fe45c56c67c69ee7e1dc538a8d43a643fc",
                "level": 2,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1538092800,
              "assignee": "d0866eb35bd85d3d9",
              "title": null,
              "endtime": 1538136600
            },
            {
              "starttime": 1538137200,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "068ec5ff1949b9241",
              "duration": 50,
              "readonly": false,
              "request_id": "068ec5ff1949b9241",
              "talk": {
                "created": 1522294584,
                "notes": "",
                "description": "OpenWhisk is an Open Source Serverless platform build out of a distributed system of components, the operations can be configure based the environment requirements. All components are docker containers deploy in a cluster. Serverless Functions also run as docker containers. In a nut shell every component is a container. We have integrated OpenWhisk and Kubernetes to provide a deployment model easy to manage and scale. I will present how OpenWhisk is compose, distributed, and orchestrated using Kubernetes and the benefits of using Kubernetes in this new deployment model. At the end the audience should walk away feeling confident that if they want to use or operate Serverless using Apache Components such as OpenWhisk, Kafka, CouchDB  is something they should be able achieve with good understanding on how to get started.",
                "tags": "serverless, openwhisk, containers, kubernetes",
                "id": "1247c96ff4edf4c31",
                "pending": false,
                "bio": "Carlos works at IBM as a Senior Technical Staff Member (STSM) on IBM Cloud Functions Architecture.\nHe is a PMC member Apache Cordova and PPMC member of Apache OpenWhisk (Incubating)  involved in leveraging open source technologies within IBM’s Cloud organization. \nHe leads the open source OpenWhisk project to get more corporations and individuals to contribute to the Serverless project.\nTwitter http:\/\/twitter.com\/csantanapr  \nGitHub http:\/\/github.com\/csantanapr  ",
                "ttype": "3cf5d8e3f090ee27c2ef29ae8",
                "request_id": "1247c96ff4edf4c31",
                "onhold": false,
                "title": "Cloud Native the Apache Way with OpenWhisk and Kubernetes",
                "speaker": "Carlos Santana",
                "conference": "apachecon-north-america-2018",
                "submitter": "2601dc9125eb127119dbbb034e3ee21d7f406a51",
                "level": 1,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1538092800,
              "assignee": "1247c96ff4edf4c31",
              "title": null,
              "endtime": 1538140200
            },
            {
              "starttime": 1538145600,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "a3a4b0cb219a6f6bd",
              "duration": 50,
              "readonly": false,
              "request_id": "a3a4b0cb219a6f6bd",
              "talk": {
                "created": 1517522558,
                "notes": "",
                "description": "Chatbots are becoming fairly popular, however open-source chatbot systems are lagging behind. We introduce a platform for transactional and question-answering chatbot based on machine learning and linguistic analysis of OpenNLP for search engineers and generalists. We will learn how to  design a dialogue manager for a given domain as well as how to populate a chatbot with knowledge. The audience will get a hands-on skills in deploying deep, conventional and inductive machine learning to syntactic and rhetoric parsing data. ",
                "tags": "chatbots, machine learning, linguistic analysis, discourse analysis",
                "id": "c842a3629aa83867a",
                "pending": false,
                "bio": "Boris Galitsky has been presenting talks on AI over last two decades and at Apache conferences over last few years. He contributed linguistic and machine learning technologies to Silicon Valley startups for last 25 years, as well as eBay and Oracle, where  he is currently an architect of Intelligent Bots project. An author of two  computer science books and 150+ publications, he is now working on a book \"Developing Enterprise Chatbots\" to be published by Springer in 2019. Boris is Apache committer to OpenNLP where he created OpenNLP.Similarity component which is a basis for chatbot development.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "c842a3629aa83867a",
                "onhold": false,
                "title": "Developing a chatbot based on OpenNLP",
                "speaker": "Boris Galitsky",
                "conference": "apachecon-north-america-2018",
                "submitter": "0abcd165e348ea3c8d193bb6ad867458cdcd80dd",
                "level": 1,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1538092800,
              "assignee": "c842a3629aa83867a",
              "title": null,
              "endtime": 1538148600
            },
            {
              "starttime": 1538149200,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "0eec47b9b549ec9f6",
              "duration": 50,
              "readonly": false,
              "request_id": "0eec47b9b549ec9f6",
              "talk": {
                "created": 1522334405,
                "notes": "",
                "description": "One area of particular strength of the Apache Groovy programming language is for writing test scripts. The language itself has numerous features making it easy to write concise but easy to read tests, there are numerous libraries specifically designed to aid writing behavior-driven tests and the powerful scripting capabilities make it easy to apply a range of useful testing techniques and approaches.\n\nWe’ll look briefly at using Groovy with JUnit and Spock and libraries for testing in special contexts, e.g. using Geb for testing web applications and microservices. We’ll cover various testing approaches such as all combinations, all-pairs, model-based testing and property-based testing. Finally, we’ll cover a few tips for writing testing DSLs.\n\nYou should attend if you want to learn how to leverage a scripting language to write powerful tests or if you want to learn about some improved agile testing practices and techniques.",
                "tags": "groovy,testing",
                "id": "933223af30e822de5",
                "pending": false,
                "bio": "Paul King has been contributing to open source projects for nearly 30 years and is an active committer on numerous projects including Groovy, GPars and Gradle. Paul speaks at international conferences, publishes in software magazines and journals, and is a co-author of Manning’s best-seller: Groovy in Action, 2nd Edition.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "933223af30e822de5",
                "onhold": false,
                "title": "Make your testing Groovy",
                "speaker": "Paul King",
                "conference": "apachecon-north-america-2018",
                "submitter": "e0a10d500a1368753c6f52fe9ca08555a5357d2b",
                "level": 1,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1538092800,
              "assignee": "933223af30e822de5",
              "title": null,
              "endtime": 1538152200
            },
            {
              "starttime": 1538152800,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "2c7f28e5a8c702809",
              "duration": 50,
              "readonly": false,
              "request_id": "2c7f28e5a8c702809",
              "talk": {
                "created": 1521110515,
                "notes": "",
                "description": "Apache Pulsar is a recently open-sourced messaging platform, originally created in Yahoo!(U.S.). Since it was designed for Yahoo!, which has tremendous traffic and a large number of services\/applications, Apache Pulsar has the following notable features by nature: Multi-tenancy, Horizontal scalability, Durability, High throughput, Low latency\n\nWe adopted Apache Pulsar to develop a centralized pub-sub messaging platform for all services\/applications in Yahoo! JAPAN. Multi-tenancy and horizontal scalability allow us to cope with a large number of services\/applications, called \"property\" in Apache Pulsar, on a single instance and increase the properties seamlessly, i.e., new properties can be added immediately without system stop. Durability, high throughput and low latency bring reliable real-time pub-sub messaging to users. Moreover, since Apache Pulsar has quite a simple Client API, users can develop their applications intuitively.\n\nWe have already provided our messaging platform in the production environment. It has been used so far by a lot of services such as Mail, Gyao (streaming video service), etc. We will introduce our actual use cases and show how Apache Pulsar works.\n\nBrief outline of our presentation:\n1. What is Apache Pulsar\n2. Why Apache Pulsar is useful\n3. How Yahoo! JAPAN uses Apache Pulsar",
                "tags": "",
                "id": "48de3718c7b01fedc",
                "pending": false,
                "bio": "Software engineer of Yahoo! JAPAN, committer of \"Apache Pulsar\":https:\/\/github.com\/apache\/incubator-pulsar.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "onhold": false,
                "request_id": "48de3718c7b01fedc",
                "title": "Apache Pulsar and its enterprise use case",
                "speaker": "Nozomi Kurihara",
                "conference": "apachecon-north-america-2018",
                "submitter": "5676b031fe293230b9a868b78360985ca8506239",
                "level": 0,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1538092800,
              "assignee": "48de3718c7b01fedc",
              "title": null,
              "endtime": 1538155800
            }
          ]
        },
        {
          "day": 1537920000,
          "slots": [
            {
              "starttime": 1537959900,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "67da27c10c366b436",
              "duration": 50,
              "readonly": false,
              "request_id": "67da27c10c366b436",
              "talk": {
                "created": 1522070019,
                "notes": "",
                "description": "What updates has been made to CloudStack Container Service (CCS)? CCS has recently been updated to support the latest CloudStack LTS version (4.11) and to support Kubernetes 1.9. We will also discuss deploying CCS in basic zones, on shared networks, and on existing isolated networks. The new features of resizing and auto-scaling of container clusters will also be explained. The talk is aimed at existing CCS users, CloudStack users, and people who would like to use Kubernetes in their clouds.",
                "tags": "CloudStack",
                "id": "52ac629bef8be0d24",
                "pending": false,
                "bio": "Henko Holtzhausen is a Software Engineer at ShapeBlue, the leading global independent integrator of Cloudstack technologies and specialists in consultancy, design and implementation of IaaS cloud infrastructure. Part of a new generation of ShapeBlue employees in South Africa, Henko shares his passion about cloud engineering with the rest of the company. In his spare time Henko enjoys all that the Cape Winelands have to offer - hiking, food and wine, riding his motorcycle and association football.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "onhold": false,
                "request_id": "52ac629bef8be0d24",
                "title": "[CloudStack]: Container Service - k8s in your cloud",
                "speaker": "Henko Holtzhausen",
                "conference": "apachecon-north-america-2018",
                "submitter": "ae800fcde39893ba2e23e445c595c8f34a5e05bb",
                "level": 0,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1537920000,
              "assignee": "52ac629bef8be0d24",
              "title": null,
              "endtime": 1537962900
            },
            {
              "starttime": 1537963500,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "1e67ad3f6db2c1816",
              "duration": 50,
              "readonly": false,
              "request_id": "1e67ad3f6db2c1816",
              "talk": {
                "created": 1522454379,
                "notes": "Userful admins",
                "description": "Currently, CloudStack doesn't understand and leverage the GPU cards installed in a VMware host. This feature will help users\/admin to assign a physical GPU(GPU-passthrough) or a portion of a physical GPU card(vGPU) to a guest VM at the time of VM deployment or at any later stage by changing the service offering. It will help run graphical applications on VMs running in CloudStack.\n\nGPU (graphics processing unit) is used for accelerating the image output in a frame buffer intended for output to a display. GPU-accelerated computing offers unprecedented application performance by offloading compute-intensive portions of the application to the GPU, while the remainder of the code still runs on the CPU. With vGPU technology, the graphics commands of each virtual machine are passed directly to the underlying dedicated GPU, without translation by the hypervisor. This allows the GPU hardware to be time-sliced and shared across multiple VMs.\n\nVMware has added support for NVIDIA GRID K1 and GRID K2 cards as well as NVIDIA Tesla M6 and Tesla M60[3][5]. It allows the VMs on ESXi hosts to use the GPU cards in following ways: GPU-passthrough\/Direct: It allows the hypervisor to assign the entire pGPU to a VM, this is useful for a power user. vGPU: It allows the VM to share a pGPU device with other VMs, this is useful for tier 2 users. But each GPU can be shared across up to eight VMs.",
                "tags": "",
                "id": "17a3bfd3b44cc1a33",
                "pending": false,
                "bio": "Sateesh is Apache CloudStack committer\n\nGPU (graphics processing unit) is used for accelerating the image output in a frame buffer intended for output to a display. GPU-accelerated computing offers unprecedented application performance by offloading compute-intensive portions of the application to the GPU, while the remainder of the code still runs on the CPU. With vGPU technology, the graphics commands of each virtual machine are passed directly to the underlying dedicated GPU, without translation by the hypervisor. This allows the GPU hardware to be time-sliced and shared across multiple VMs.\n\nVMware has added support for NVIDIA GRID K1 and GRID K2 cards as well as NVIDIA Tesla M6 and Tesla M60[3][5]. It allows the VMs on ESXi hosts to use the GPU cards in following ways: GPU-passthrough\/Direct: It allows the hypervisor to assign the entire pGPU to a VM, this is useful for a power user. vGPU: It allows the VM to share a pGPU device with other VMs, this is useful for tier 2 users. But each GPU can be shared across up to eight VMs.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "17a3bfd3b44cc1a33",
                "onhold": false,
                "title": "GPU\/vGPU Support in CloudStack",
                "speaker": "Sateesh Chodapuneedi",
                "conference": "apachecon-north-america-2018",
                "submitter": "c40bc5e859d22997067009e62e32645da742750c",
                "level": 1,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1537920000,
              "assignee": "17a3bfd3b44cc1a33",
              "title": null,
              "endtime": 1537966500
            },
            {
              "starttime": 1537972200,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "3969ca02bc75114a4",
              "duration": 50,
              "readonly": false,
              "request_id": "3969ca02bc75114a4",
              "talk": {
                "created": 1521746032,
                "notes": "",
                "description": "In its original incarnations, CloudStack was not designed to support storage Quality of Service (sQoS). However, as CloudStack is a Cloud Management Platform that targets production environments running mission-critical applications, sQoS is an important feature to offer.\n\nIn this presentation, I walk the audience through what Managed Storage is, how it relates to sQoS, and then provide a demo of the powerful features CloudStack now offers with its Managed Storage implementation.\n\nEven though sQoS is the primary driver for Managed Storage, there are other benefits Managed Storage can convey, such as fast and efficient snapshots. This is also discussed and demoed.",
                "tags": "CloudStack Storage QoS",
                "id": "1d99b41248b72da21",
                "pending": false,
                "bio": "Mike Tutkowski is the Senior CloudStack Developer at SolidFire. Mike develops software for the Apache Software Foundation's CloudStack project. He is experienced in CloudStack storage, a member of the Project Management Committee for the Apache CloudStack project, and plays a critical role in developing and expanding SolidFire’s integration with CloudStack.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "1d99b41248b72da21",
                "onhold": false,
                "title": "CloudStack: What is Managed Storage? Demo",
                "speaker": "Mike Tutkowski",
                "conference": "apachecon-north-america-2018",
                "submitter": "cde2431306cbb18b3deaa469ddf838c4aebec922",
                "level": 0,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1537920000,
              "assignee": "1d99b41248b72da21",
              "title": null,
              "endtime": 1537975200
            },
            {
              "starttime": 1537975800,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "b825ea692e8308964",
              "duration": 50,
              "readonly": false,
              "request_id": "b825ea692e8308964",
              "talk": {
                "created": 1522065466,
                "notes": "",
                "description": "Usual template\/ISO registration implies downloading them to secondary storage and then copy them to primary storage on a VM deployment. This talk shows a way to avoid the intermediate secondary storage cache and only downloading templates\/ISOs to primary storage when needed.",
                "tags": "",
                "id": "bbc49bea18dfedf78",
                "pending": false,
                "bio": "Nicolas Vazquez is a Software Engineer at ShapeBlue, the leading global independent integrator of CloudStack technologies and specialists in consultancy, design and implementation of IaaS cloud infrastructure. Nicolas has 6 years experience as a developer and 3 years experience on CloudStack on which he is a commiter. In his spare time Nicolas likes playing football (soccer) or tennis",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "bbc49bea18dfedf78",
                "onhold": false,
                "title": "[CloudStack]: Bypass Secondary Storage",
                "speaker": "Nicolas Vazquez",
                "conference": "apachecon-north-america-2018",
                "submitter": "c98e03293e58011b4e6ccaf29dc849f838764de1",
                "level": 1,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1537920000,
              "assignee": "bbc49bea18dfedf78",
              "title": null,
              "endtime": 1537978800
            },
            {
              "starttime": 1537980000,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "990c8258ba9d0683c",
              "duration": 50,
              "readonly": false,
              "request_id": "990c8258ba9d0683c",
              "talk": {
                "created": 1522065364,
                "notes": "",
                "description": "For the Apache Cloudstack project, discuss the various practical use cases and improvements that have been made to the private gateway of a VPC (Virtual Private Cloud).",
                "tags": "networking, Virtual Private Cloud, Private Gateway",
                "id": "ab597c13d13cf6ba8",
                "pending": false,
                "bio": "Ernie is a Software Engineer at ShapeBlue, the leading global independent integrator of Cloudstack technologies and specialises in consultancy, design and implementation of IaaS cloud infrastructure. ",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "ab597c13d13cf6ba8",
                "onhold": false,
                "title": "VPC private gateway practical uses and improvements",
                "speaker": "Ernie Janse van Rensburg",
                "conference": "apachecon-north-america-2018",
                "submitter": "a2ae172073cf03d5dbf8fc7a4c3a31c1b7233925",
                "level": 1,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1537920000,
              "assignee": "ab597c13d13cf6ba8",
              "title": null,
              "endtime": 1537983000
            }
          ]
        },
        {
          "day": 1537833600,
          "slots": [
            {
              "starttime": 1537866000,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "941cd586764a4a833",
              "duration": 50,
              "readonly": false,
              "request_id": "941cd586764a4a833",
              "talk": {
                "created": 1524061520,
                "notes": "",
                "description": "Welcome to CloudStack Collaboration Conference\n\nThe CCC events are an opertunity for the Apache CloudStack® community to come together and share their work and experiences.",
                "tags": "cloudstack",
                "id": "c096e0e6db072051a",
                "pending": false,
                "bio": "Mike Tutkowski is the Senior CloudStack Developer at SolidFire. Mike develops software for the Apache Software Foundation's CloudStack project. He is experienced in CloudStack storage, a member of the Project Management Committee for the Apache CloudStack project, and plays a critical role in developing and expanding SolidFire’s integration with CloudStack.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "c096e0e6db072051a",
                "onhold": false,
                "title": "Welcome to CloudStack Collaboration Conference",
                "speaker": "Mike Tutowski",
                "conference": "apachecon-north-america-2018",
                "submitter": "6e13ead734e1e92ba4ea121e5d8a67280d0f4614",
                "level": 0,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1537833600,
              "assignee": "c096e0e6db072051a",
              "title": null,
              "endtime": 1537869000
            },
            {
              "starttime": 1537869600,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "3fab92638e336277a",
              "duration": 50,
              "readonly": false,
              "request_id": "3fab92638e336277a",
              "talk": {
                "created": 1522228852,
                "notes": "",
                "description": "This presentation will look at CloudStack's current relationship with NFV. And show the recent and ongoing work to enable users to create complex networking topologies using CloudStack. ",
                "tags": "",
                "id": "4ad1205d611eaf90a",
                "pending": false,
                "bio": "Paul is VP Technology \/ Cloud Architect for ShapeBlue and an Apache CloudStack Project Management Committee member . He consults to a number of large service providers and enterprises. In is responsible for ShapeBlue's technical strategy. Paul has spoken at every CloudStack Collaboration Conference as well as speaking for Ansible at a number of events. Paul has worked with clients such as Interoute, SAP, Orange Telecom, SunGard AS, Sky, TomTom and British Telecom.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "4ad1205d611eaf90a",
                "onhold": false,
                "title": "[CloudStack] Complex Network Topologies in CloudStack",
                "speaker": "Paul Angus",
                "conference": "apachecon-north-america-2018",
                "submitter": "09b0bb6a99e62b912e20f6fc12198c9b446e8609",
                "level": 1,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1537833600,
              "assignee": "4ad1205d611eaf90a",
              "title": null,
              "endtime": 1537872600
            },
            {
              "starttime": 1537874400,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "473d239cbf193a6da",
              "duration": 50,
              "readonly": false,
              "request_id": "473d239cbf193a6da",
              "talk": {
                "created": 1522068338,
                "notes": "wifi and beamer",
                "description": "CloudStack users will wish to be able to back up their guest VMs for recovery purposes should they suffer a hardware or software issue with their instance(s) or on the underlying infrastructure. The old mechanism which users leverage is the volume snapshot feature as this has the feature set closest to that of a backup regime. i.e. images are stored on alternate location (although this may actually be the same physical array), it can be scheduled, and users can set how many backups can be kept. The volume snapshot mechanism causes a VM snapshot to be taken, then the required volume transferred to secondary storage from a hypervisor host in the cluster within which the VM resides. In the case of VMware, the image is compressed into an OVA by the SSVM. \nThis talk describes a framework for implementing plugins of third party backup vendor products into cloudstack. A highlevel SLA definition scheme is defined in terms of abstract methods that will be implemented by vendor plugins. In addition a set of implementation which are under development will be shown.",
                "tags": "ACS Cloudstack",
                "id": "ae4b3e5978fb1de10",
                "pending": false,
                "bio": "Daan Hoogland is a developer at ShapeBlue, the leading global independent integrator of Cloudstack technologies and specialists in consultancy, design and implementation of IaaS cloud infrastructure. \nDaan Hoogland is and has been a developer\/operator for thirty years. He is multilingual and is against code not making it to production and production code not being reliable. A dilemma that gives joy like a dirty mind.\nIn his spare time Daan is enjoying triathlon and darts.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "onhold": false,
                "request_id": "ae4b3e5978fb1de10",
                "title": "[CLOUDSTACK]:backup and recovery framework",
                "speaker": "Daan",
                "conference": "apachecon-north-america-2018",
                "submitter": "dbb70be90127640a6e25a3a828e850b1fe46df99",
                "level": 0,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1537833600,
              "assignee": "ae4b3e5978fb1de10",
              "title": null,
              "endtime": 1537877400
            },
            {
              "starttime": 1537878000,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "c1fd4918661748e19",
              "duration": 50,
              "readonly": false,
              "request_id": "c1fd4918661748e19",
              "talk": {
                "created": 1522436266,
                "notes": "",
                "description": "Present Cloudstack integration with Vault by HashiCorp on different grounds:\n- as PKI backend engine, to generate self-signed Certificates for VPN implementation on VRs\n- as Secret engine, to store general username\/password (system's and customer's)\n- as SSH backend engine, to store predefined or generate one-time only on the fly SSH keys (for CPVM, SSVM, and normal VMs in general)",
                "tags": "cloudstack,vault,hashicorp",
                "id": "05f9441cd381ab82e",
                "pending": false,
                "bio": "Cloud Infrastructure Developer at CloudOps, contributor to Apache Cloudstack and Java Vault driver. with more than a decade experience in the industry.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "05f9441cd381ab82e",
                "onhold": false,
                "title": "CloudStack integration with Vault by HashiCorp",
                "speaker": "Khosrow Moossavi",
                "conference": "apachecon-north-america-2018",
                "submitter": "4235462a0b75c0e05768704d0f4decfa7f2bbd4e",
                "level": 2,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1537833600,
              "assignee": "05f9441cd381ab82e",
              "title": null,
              "endtime": 1537881000
            },
            {
              "starttime": 1537886400,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "2602b88ea93a6be90",
              "duration": 50,
              "readonly": false,
              "request_id": "2602b88ea93a6be90",
              "talk": {
                "created": 1522322180,
                "notes": "",
                "description": "The talk is about the CloudStack Virtual Router. In this talk, the speaker will give a brief history of systemvmtemplate and origins of Virtual Router. It will cover the current state of VR\/SDN in CloudStack, recent systemvmtemplate improvements, how the VR is provisioned and programmed, and currently upgraded. Finally, it will cover the future of Virtual Routers, the scope of improvements and roadmap for discussions.",
                "tags": "",
                "id": "520317717889c9ca9",
                "pending": false,
                "bio": "Rohit Yadav is a long-term Apache CloudStack committer and a PMC member. He is the author and maintainer of cloudmonkey and has been the release manager for 4.11\/LTS and maintainer\/RM for several other older minor releases.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "520317717889c9ca9",
                "onhold": false,
                "title": "Virtual Router - Past, Present and Future",
                "speaker": "Rohit Yadav",
                "conference": "apachecon-north-america-2018",
                "submitter": "73131dfc485adca65c412a237e64def26ddd3693",
                "level": 1,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1537833600,
              "assignee": "520317717889c9ca9",
              "title": null,
              "endtime": 1537889400
            },
            {
              "starttime": 1537890000,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "2ef695d0a8e94c2ed",
              "duration": 50,
              "readonly": false,
              "request_id": "2ef695d0a8e94c2ed",
              "talk": {
                "created": 1522410981,
                "notes": "",
                "description": "This is a need to improvement volume and snapshot operations in Apache CloudStack. Focus on current volume and snapshot operations and their improvement areas.",
                "tags": "",
                "id": "c051c26735531b58c",
                "pending": false,
                "bio": "Suresh Anaparti has 13+ years of product development experience in Networking, Cloud Infrastructure and VoIP Technologies. He is an Apache CloudStack contributor. He has been working on CloudStack development since last 3 years and was mainly working on Orchestration part, Job Framework, CPVM, SSVM,  Volumes, Snapshots and VMware hypervisor resource, in particular.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "c051c26735531b58c",
                "onhold": false,
                "title": "Volume and Snapshot Improvements in Apache Cloudstack",
                "speaker": "Suresh Kumar Anaparti",
                "conference": "apachecon-north-america-2018",
                "submitter": "42a4073f1edb4e9319ce9a0bd1c0eaa9784d4cf0",
                "level": 0,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1537833600,
              "assignee": "c051c26735531b58c",
              "title": null,
              "endtime": 1537893000
            },
            {
              "starttime": 1537893600,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "d330460f5a0e75d8b",
              "duration": 50,
              "readonly": false,
              "request_id": "d330460f5a0e75d8b",
              "talk": {
                "created": 1522147957,
                "notes": "Normal presentation, projector and wifi only required.",
                "description": "This talk will explain the functionality of the remote diagnostics tools being put in place in CloudStack. These API calls assist the CloudStack operator in getting troubleshooting data automatically gathered in a central location for quicker troubleshooting and resolution of problems. The talk will cover current functionality as well as discuss future options for expansions.",
                "tags": "cloudstack,diagnostics",
                "id": "43e3bf7c38f86fa8e",
                "pending": false,
                "bio": "Dingane Hlaluku is a Cloud Software Engineer at ShapeBlue, the leading global independent integrator of Cloudstack technologies and specialists in consultancy, design and implementation of IaaS cloud infrastructure. Dingane has a Master's Degree in physics from the University of Witwatersrand in Johannesburg and has previously worked at CERN in Switzerland. Dingane is working with the ShapeBlue team and CloudStack community on new features in Apache CloudStack. ",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "43e3bf7c38f86fa8e",
                "onhold": false,
                "title": "[CloudStack]:Remote diagnostics in CloudStack",
                "speaker": "Dingane Hlaluku",
                "conference": "apachecon-north-america-2018",
                "submitter": "991906e74de30774c29c3107f1fef2727b2ca8a6",
                "level": 1,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1537833600,
              "assignee": "43e3bf7c38f86fa8e",
              "title": null,
              "endtime": 1537896600
            },
            {
              "starttime": 1537896300,
              "origin": "6f2a4d4b2751e7f8f",
              "id": "f8fdabac1314eec5b",
              "duration": 50,
              "readonly": false,
              "request_id": "f8fdabac1314eec5b",
              "talk": {
                "created": 1522070288,
                "notes": "No special requirements, a projector and mic will be good enough. ",
                "description": "This talk is about one of the latests features in 4.11 that offers a simple way to manage the agent connections load within an environment with multiple management servers. It gives the user a way to configure a few predefined algorithms for distributing the cloudstack-agent connections across a pool of management server without any other hardware or software equipment other than Apache CloudStack installed. ",
                "tags": "cloudstack, load-balancing, managements, agents, kvm",
                "id": "29a1f805812130bb6",
                "pending": false,
                "bio": "Boris Stoyanov is a Software Engineer at ShapeBlue, the leading global independent integrator of CloudStack technologies and specialists in consultancy, design and implementation of IaaS cloud infrastructure. Boris is Experienced QA and Test Automation Developer with background in different business domains and tools. Expert in creating Test Automation Frameworks using different platforms, tools and programming languages. He's with the ACS family since 2016 and has been contributing by testing most of the new features and releases of ACS since then. In his spare time he enjoys traveling, sports and family. Boris has in the past presented talks at ApacheCon, CloudStack Collaboration Conferences as well as a number of other CloudStack and Virtualization meet-ups and user groups. ",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "29a1f805812130bb6",
                "onhold": false,
                "title": "[CloudStack] Load Balancing CloudStack Agent Connections",
                "speaker": "Boris Stoyanov",
                "conference": "apachecon-north-america-2018",
                "submitter": "52326dc742497520eb72f3fce95c5254e894e71b",
                "level": 1,
                "accepted": true
              },
              "room": "6f2a4d4b2751e7f8f",
              "day": 1537833600,
              "assignee": "29a1f805812130bb6",
              "title": null,
              "endtime": 1537899300
            }
          ]
        }
      ]
    },
    {
      "id": "3a98f01da63498d05",
      "name": "Track4",
      "days": [
        {
          "day": 1537920000,
          "slots": [
            {
              "starttime": 1537959900,
              "origin": "3a98f01da63498d05",
              "id": "bac4e8cf204d93d90",
              "duration": 50,
              "readonly": false,
              "request_id": "bac4e8cf204d93d90",
              "talk": {
                "created": 1522323795,
                "notes": "",
                "description": "Apache Fineract-CN-mobile native android application built on the top of Apache Fineract-CN. Apache Fineract CN is an Application Framework for Digital Financial Services. It is a system to support nationwide financial transactions and to support the creation of an inclusive, interconnected digital economy for every nation in the world. \n\nWith the rise of mobile devices and fast access to any type of data. I present Apache Fineract-CN-mobile that is a very advanced level of android application and maintained with high standards architecture. Its codebase is too simple as it was in starting and we are building new advanced feature with advanced libraries. it solves the biggest problem of financial institutions like \n\n1. Maintainability and scalability with MVP architecture.\n2. Advanced level architecture that enables to upgrade advance libraries and give the ability to introduce any high-level codebase layer.\n3. Advance level security to access the app does not matter user have the internet connection or not.\n4. Simple and easy learnable UI & UX.\n5. Work with poor connectivity. \n6. Offline usage of the app (Many counties like Africa, Indonesia etc have very slow internet connectivity).\n\nI will be talking about above problems that we solved on the very high level. I will guide developers how they can pick up the codebase and can develop high standard features according to his\/her need  and can manage customers entirely from his\/her Android device and How Fineract-CN-mobile helps alleviate poverty and make the banking paperless.",
                "tags": "Android",
                "id": "238863218ab4f8169",
                "pending": false,
                "bio": "I am Rajan Maurya, working as a Android Engineer at iDT Labs, where I am building android technologies. I am a committer to the Apache Fineract and Taverna and I have successfully graduated Google Summer of Code twice from Mifos Initiative and Apache. Apart from my job I am open source developer and contribute to Apache Fineract, Mifos Initiative and Taverna android projects and maintain their android projects too. ",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "238863218ab4f8169",
                "onhold": false,
                "title": "Apache Fineract CN mobile - Supporting Branchless banking and promoting financial inclusion in the fragile states",
                "speaker": "Rajan Maurya",
                "conference": "apachecon-north-america-2018",
                "submitter": "282b8b666b4b6b3de4ac2569052295c3a8f8b7ca",
                "level": 1,
                "accepted": true
              },
              "room": "3a98f01da63498d05",
              "day": 1537920000,
              "assignee": "238863218ab4f8169",
              "title": "11:05 -> 11:55 (50 min)",
              "endtime": 1537962900
            },
            {
              "starttime": 1537963500,
              "origin": "3a98f01da63498d05",
              "id": "9438311697149af61",
              "duration": 50,
              "readonly": false,
              "request_id": "9438311697149af61",
              "talk": {
                "created": 1522260456,
                "notes": "",
                "description": "While the banking industry is finally waking up to open source software, the Mifos project has for the past 16 years staked out a position of 100% open source for a full banking application.\n\nCommitted to developing a platform which supports the unbanked around the world, the Mifos Initiative contributed its Mifos X platform to the Apache Software Foundation as Apache Fineract in 2016.\n\nAlthough we started in the underserved market of microfinance banks and microcredit programs, we’ve seen recent uptake in our ecosystem by major payment companies and larger banks.\n\nWe'll discuss the use of Apache Fineract in four key enterprise financial service initiatives and lessons learned in pitching open source to banking and payment corporations, the widespread effects of adopting it, and transforming banks from consumers to contributors.\n\nMexico – at a Mexican bank they’ve built their innovation lab on top of Apache Fineract allowing the bank to bypass an expensive procurement process with existing vendors who would charge for every change.\nIndia – at a major Indian Payments platform, our system maintains the agent network, the core account management, and liquidity management that’s allowed them to scale to millions but have had challenges getting management to acknowledge and embrace the vision of open source.\nNigeria – at a Palo Alto startup focused on financial inclusion in Nigeria, we’ve integrated with their machine learning based credit scoring engine yet faced challenges in responding to their unique requirements.\nGermany – at a bank in Germany, one of our value-added companies has sold the management on open source as a way to offer new innovative services.\n\nIn each case study, we’ll highlight:\n\n* Adopting Open Source – the sales cycle in getting senior management at enterprise financial institutions to explore and embrace open source.\n* Implementing Open Source – the impact to the bottom line and culture of the organization by lowering costs, increasing innovation, and giving ownership and control to internal stakeholders.\n* Contributing to Open Source – the challenge in convincing leadership to become members of the open source community – from simply acknowledging it to evangelizing it to actively contributing to it.\n",
                "tags": "fintech, banking, financial inclusion, ",
                "id": "716e929c30a8a65cc",
                "pending": false,
                "bio": "Leader of Mifos Initiative, the non-profit initiative and global open source community building fintech solutions for the unbanked on top of Apache Fineract. Ed is a passionate changemaker helping fuel poverty alleviation through financial inclusion, open source technology, and the power of community.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "716e929c30a8a65cc",
                "onhold": false,
                "title": "Open Banking: Fueling Innovation on an Open Source Core Banking Platform",
                "speaker": "Ed Cable",
                "conference": "apachecon-north-america-2018",
                "submitter": "93d11f22ac7d22ed669321cb0a95290ac4324b7c",
                "level": 0,
                "accepted": true
              },
              "room": "3a98f01da63498d05",
              "day": 1537920000,
              "assignee": "716e929c30a8a65cc",
              "title": "12:05 -> 12:55 (50 min)",
              "endtime": 1537966500
            },
            {
              "starttime": 1537972200,
              "origin": "3a98f01da63498d05",
              "id": "97d258b468cd32901",
              "duration": 50,
              "readonly": false,
              "request_id": "97d258b468cd32901",
              "talk": {
                "created": 1522331044,
                "notes": "",
                "description": "Apache Fineract-CN-mobile native android application built on the top of Apache Fineract-CN. Apache Fineract CN is an Application Framework for Digital Financial Services. It is a system to support nationwide financial transactions and to support the creation of an inclusive, interconnected digital economy for every nation in the world. \n\nWith the rise of mobile devices and fast access to any type of data. I present Apache Fineract-CN-mobile that is a very advanced level of android application and maintained with high standards architecture. Its codebase is too simple as it was in starting and we are building new advanced feature with advanced libraries. it solves the biggest problem of financial institutions like \n\n1. Maintainability and scalability with MVP architecture.\n2. Advanced level architecture that enables to upgrade advance libraries and give the ability to introduce any high-level codebase layer.\n3. Advance level security to access the app does not matter user have the internet connection or not.\n4. Simple and easy learnable UI & UX.\n5. Work with poor connectivity. \n6. Offline usage of the app (Many counties like Africa, Indonesia etc have very slow internet connectivity).\n\nI will be talking about above problems that we solved on the very high level. I will guide developers how they can pick up the codebase and can develop high standard features according to his\/her need and can manage customers entirely from his\/her Android device and How Fineract-CN-mobile helps alleviate poverty and make the banking paperless.",
                "tags": "Android",
                "id": "79e2588a4b7801060",
                "pending": false,
                "bio": "I am Rajan Maurya, working as a Android Engineer at iDT Labs, where I am building android technologies. I am a committer to the Apache Fineract and Taverna and I have successfully graduated Google Summer of Code twice from Mifos Initiative and Apache. Apart from my job I am open source developer and contribute to Apache Fineract, Mifos Initiative and Taverna android projects and maintain their android projects too. ",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "79e2588a4b7801060",
                "onhold": false,
                "title": "Apache Fineract CN mobile - Supporting Branchless banking and promoting financial inclusion in the fragile states",
                "speaker": "Rajan Maurya",
                "conference": "apachecon-north-america-2018",
                "submitter": "282b8b666b4b6b3de4ac2569052295c3a8f8b7ca",
                "level": 1,
                "accepted": true
              },
              "room": "3a98f01da63498d05",
              "day": 1537920000,
              "assignee": "79e2588a4b7801060",
              "title": "14:30 -> 15:20 (50 min)",
              "endtime": 1537975200
            },
            {
              "starttime": 1537975800,
              "origin": "3a98f01da63498d05",
              "id": "481556b80c27454b5",
              "duration": 50,
              "readonly": false,
              "request_id": "481556b80c27454b5",
              "talk": {
                "created": 1518186750,
                "notes": "",
                "description": "Deep Learning is tremendously popular and hot recently. Although building neural network is the core of deep learning, people usually underestimate other steps of deep learning, such as data pre-processing, training process visualization and hyper-parameter tuning. You will get a unworkable model if any of these step goes wrong. So it is essentially important to do all these steps carefully and effectively. But each step will involve different tools and technique, switching between them is annoying and inefficient. \n\nApache Zeppelin is a web-based notebook that enables data-driven, interactive data analytics and collaborative documents with SQL, Python, Scala and more. With its spark interpreter, you can do raw data pre-processing. With its spark interpreter, you can do raw data pre-processing. With its python interpreter, you can run most of the deep learning libraries. And you can visualize the training process and tune model hyper-parameter via its visualization capability. Besides that Zeppelin provide other features like multi-tenancy, collaboration, dynamic forms and etc. All these function will improve your productivity in deep learning.\n \nIn this talk, I will talk about how to do deep learning in Apache Zeppelin notebook via a simple demo including data pre-processing, building neural network, parameter tuning and monitoring training process. \n",
                "tags": "ApacheZeppelin,DeepLearning,Keras",
                "id": "643cc913ebc25db3f",
                "pending": false,
                "bio": "Jeff Zhang has 9 years of experience in big data industry. He started to use hadoop since 2009 and is a member of apache software foundation, committer of multiple apache projects ( Pig\/Tez\/Zeppelin\/Livy). His past experience is not only on big data infrastructure, but also on how to leverage these big data tools to get insight. He speaks several times in big data conferences like hadoop summit, strata data conference and apache big data conference. Now he works in hortonworks as member of technical staff. \n\nHortonworks is a leading innovator in the industry, creating, distributing and supporting enterprise-ready open data platforms and modern data applications.\n",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "onhold": false,
                "request_id": "643cc913ebc25db3f",
                "title": "Deep Learning in Apache Zeppelin Notebook",
                "speaker": "Jeff Zhang",
                "conference": "apachecon-north-america-2018",
                "submitter": "6cfaf7a404a4762f583c585fe5ce8f5d02d4faf4",
                "level": 0,
                "accepted": true
              },
              "room": "3a98f01da63498d05",
              "day": 1537920000,
              "assignee": "643cc913ebc25db3f",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537978800
            },
            {
              "starttime": 1537980000,
              "origin": "3a98f01da63498d05",
              "id": "55e6d8cd89059be5e",
              "duration": 50,
              "readonly": false,
              "request_id": "55e6d8cd89059be5e",
              "talk": {
                "created": 1522372301,
                "notes": "",
                "description": "Pub-Sub messaging is a very convenient abstraction that allows system and application developers to decouple components and let them communicate, by acting as durable buffer for transient data, or as a persistent log from where to recover after crashes. This talk will present an overview of Apache Pulsar, the reasons that led to its development and how it enabled many teams at Yahoo and to build scalable and reliable applications. Apache Pulsar has become the defacto pub-sub messaging at Yahoo serving 100+ applications and processing 100’s of billions of messages for over 3+ years.\n\nIn this talk, we will explore in detail different categories of use cases that highlight how Pulsar can be applied to solve a broad range of problems thanks to its flexible messaging model that supports both queuing and streaming semantics with a focus on durability and transaction guarantees.\n",
                "tags": "",
                "id": "0f42e03c8d0ff9537",
                "pending": false,
                "bio": "Matteo Merli is a software engineer at Streamlio working on messaging and storage technologies. Prior to Streamlio, he spent several years at Yahoo building database replication systems and multi-tenant messaging platforms. He is the co-creator of Apache Pulsar and a member of the PMC of Apache BookKeeper.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "0f42e03c8d0ff9537",
                "onhold": false,
                "title": "Apache Pulsar - Flexible Pub-Sub System at Internet scale",
                "speaker": "Matteo Merli",
                "conference": "apachecon-north-america-2018",
                "submitter": "9bd65e25566167609900fb2ab5fba98a6cbfc6b2",
                "level": 0,
                "accepted": true
              },
              "room": "3a98f01da63498d05",
              "day": 1537920000,
              "assignee": "0f42e03c8d0ff9537",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537983000
            }
          ]
        },
        {
          "day": 1538092800,
          "slots": [
            {
              "starttime": 1538125200,
              "origin": "3a98f01da63498d05",
              "id": "e3575eade861e0304",
              "duration": 50,
              "readonly": false,
              "request_id": "e3575eade861e0304",
              "talk": {
                "created": 1522421457,
                "notes": "",
                "description": "At the past few ApacheCon NA conferences, there have been ongoing discussions about how to improve web application load balancing, making it better...and smarter. Generally speaking, load balancing is still pretty dumb:\n\nAre the backend servers up?\nAre they successfully responding to requests?\nAre they responding in a \"timely\" manner?\nAre any particular backend servers receiving more or fewer requests than the others?\n\nThis is usually about all the information a frontend balancer has to choose the \"best\" backend for a request. Sure, some applications may provide a custom check or status page that the frontend might use to look for specific status codes or response text to help make a \"better\" decision. More often than not, though, it seems that balancers often end up reverting to a default round-robin posture that may or may not be best for their backend applications.\n\nIn this session, we will discuss some of the ideas that have been shared and refined over the past few years. The goal of these proposals is to allow proxies and load balancers to make truly informed decisions by using specific server and application state information provided by the backend itself. This backend information may incorporate factors outside the web application itself, for example high resource utilization by other server processes or a number of requests originating on other frontends or external applications. This will allow the load balancer to truly make a \"better\" -- if still not the \"best\" -- choice. Furthermore, this information could also be used for other purposes, such as monitoring, graphing, and trending.\n\nOf course, as Linus has said, \"Talks is cheap. Show me the code.\" So, we will demo and test proof-of-concept code for Apache httpd and Tomcat. With products like these and others like Traffic Server on board, perhaps ASF projects can kickstart an initiative\/standard that will spread to other projects and vendors to make load balancers a lot smarter than they are today, industry-wide!",
                "tags": "httpd, tomcat, traffic server, load balancing, proxy, web, http",
                "id": "9807e7e9a384e2fd8",
                "pending": false,
                "bio": "Jim has been a System Administrator for over fifteen years, currently with Ingram Content Group and previously with Dave Ramsey's company, both in the Nashville area. He builds and maintains Unix\/Linux environments for high-traffic web sites and applications, focusing on security and reliability.\n\nIn addition to system administration, Jim also has a development background, including eight years of software engineering at Verizon before moving to full-time systems work. His distinctive approach to projects and issues from an administration viewpoint, backed by development expertise (\"OpsDev\"), has allowed Jim to uniquely contribute to several development-centered (\"DevOps\") workplaces and open source projects. He has made contributions of varying degrees to the following communities over many years: Apache httpd, Tomcat, FreeBSD, Puppet, Ansible, PFSense, and Drupal, among others.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "9807e7e9a384e2fd8",
                "onhold": false,
                "title": "Smarter Load Balancers: Making Informed Decisions",
                "speaker": "Jim Riggs",
                "conference": "apachecon-north-america-2018",
                "submitter": "c03330c4ee26b554e21bf540cafc07e0cbaebc0b",
                "level": 1,
                "accepted": true
              },
              "room": "3a98f01da63498d05",
              "day": 1538092800,
              "assignee": "9807e7e9a384e2fd8",
              "title": "09:00 -> 09:50 (50 min)",
              "endtime": 1538128200
            },
            {
              "starttime": 1538128800,
              "origin": "3a98f01da63498d05",
              "id": "812c61cdc970e12ce",
              "duration": 50,
              "readonly": false,
              "request_id": "812c61cdc970e12ce",
              "talk": {
                "created": 1519382863,
                "notes": "",
                "description": "This session introduces Apache Kafka, an event-driven open source streaming platform. Apache Kafka goes far beyond scalable, high volume messaging. In addition, you can leverage Kafka Connect for integration and the Kafka Streams API for building lightweight stream processing microservices in autonomous teams. The open source Confluent Platform adds further components such as a Schema Registry, REST Proxy, KSQL, Clients for different programming languages and Connectors for different technologies. The session discusses how tech giants like LinkedIn, Ebay or Uber leverage Apache Kafka to solve different business problems. A live demo shows how you can easily setup a scalable streaming cluster, how to develop with Apache Kafka in different programming languages like Java, Scala, Go or Python, and how to run on cutting edge cloud platforms such as Kubernetes or Apache Mesos.\n",
                "tags": "Kafka",
                "id": "2a5e05c39913f3247",
                "pending": false,
                "bio": "Kai Waehner works as Technology Evangelist at Confluent. Kai’s main area of expertise lies within the fields of Big Data Analytics, Machine Learning \/ Deep Learning, Messaging, Integration, Microservices, Stream Processing, Internet of Things and Blockchain. He is regular speaker at international conferences such as JavaOne, O’Reilly Software Architecture or ApacheCon, writes articles for professional journals, and shares his experiences with new technologies on his blog (www.kai-waehner.de\/blog). Contact and references: kontakt@kai-waehner.de \/ @KaiWaehner \/ www.kai-waehner.de\n",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "2a5e05c39913f3247",
                "onhold": false,
                "title": "Introduction to Apache Kafka as Event-Driven Open Source Streaming Platform",
                "speaker": "Kai Wähner",
                "conference": "apachecon-north-america-2018",
                "submitter": "79836955c30623ea0d7c3afb5ccd703090fb76c4",
                "level": 0,
                "accepted": true
              },
              "room": "3a98f01da63498d05",
              "day": 1538092800,
              "assignee": "2a5e05c39913f3247",
              "title": "10:00 -> 10:50 (50 min)",
              "endtime": 1538131800
            },
            {
              "starttime": 1538133600,
              "origin": "3a98f01da63498d05",
              "id": "4e8e71e88f6c4e749",
              "duration": 50,
              "readonly": false,
              "request_id": "4e8e71e88f6c4e749",
              "talk": {
                "created": 1517227464,
                "notes": "",
                "description": "Apache Zeppelin is web-based notebook that enables data-driven, interactive data analytics and collaborative documents with SQL, Scala and more. The Zeppelin Community make a great effort to improve the Python user experience in its recent 0.8.0 release. Python user will find the user experience in Zeppelin is almost the same as Jupyter, but with better Spark support and other useful enterprise features. Most of the features of Python in Jupyter is available in Apache Zeppelin, such as code completion, magic methods, inline plotting and etc. Besides that, Zeppelin enhance the Python interpreter via ZeppelinContext  so that user could use dynamic form to improve the interactivity. With Zeppelin's other features like multi-user support, security and etc make it more suitable for enterprise adoption\n\nIn this talk, we would talk how we make Python user experience revolution and how Pythonista could use Apache Zeppelin do data analysis effectively and efficiently by taking advantage of its python interpreter features and other enterprise features.\n",
                "tags": "BigData,Zeppelin,Notebook",
                "id": "be394888021124eea",
                "pending": false,
                "bio": "Jeff Zhang has around 10 years of experience in big data industry. He started to use hadoop since 2008 and is a member of apache software foundation, committer of multiple apache projects ( Pig\/Tez\/Zeppelin\/Livy). His past experience is not only on big data infrastructure, but also on how to leverage these big data tools to get insight. He speaks several times in big data conferences like hadoop summit, strata data conference and apache big data conference. Now he works in hortonworks as member of technical staff. \n\n",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "onhold": false,
                "request_id": "be394888021124eea",
                "title": "Revolution of Python User Experience in Apache Zeppelin Notebook",
                "speaker": "Jianfeng Zhang",
                "conference": "apachecon-north-america-2018",
                "submitter": "6cfaf7a404a4762f583c585fe5ce8f5d02d4faf4",
                "level": 0,
                "accepted": true
              },
              "room": "3a98f01da63498d05",
              "day": 1538092800,
              "assignee": "be394888021124eea",
              "title": "11:20 -> 12:10 (50 min)",
              "endtime": 1538136600
            },
            {
              "starttime": 1538137200,
              "origin": "3a98f01da63498d05",
              "id": "0a2fd20f34576c371",
              "duration": 50,
              "readonly": false,
              "request_id": "0a2fd20f34576c371",
              "talk": {
                "created": 1517497513,
                "notes": "Just a screen.",
                "description": "\nIn my talk I will discuss and show examples of using Apache Hadoop, Apache Hive, Apache MXNet, Apache OpenNLP, Apache NiFi and Apache Spark for deep learning applications.\n\nAs part of my talk I will walk through using Apache NXNet Pre-Built Models, MXNet's New Model Server with Apache NiFi, executing MXNet with Apache NiFi and running Apache MXNet on edge nodes utilizing Python and Apache MiniFi.\n\nThis talk is geared towards Data Engineers interested in the basics of Deep Learning with open source Apache tools in a Big Data environment.  I will walk through source code examples available in github and run the code live on an Apache Hadoop \/ YARN \/ Apache Spark cluster.\n\nThis will be an introduction to executing Deep Learning Pipelines in an Apache Big Data environment.\n\nMy talk at Data Works Summit Sydney was listed in top 7 -&gt; https:\/\/hortonworks.com\/blog\/7-sessions-dataworks-summit-sydney-see\/\n\nAlso have speak at and run Future of Data Princeton and at Oracle Code NYC.\n\nhttps:\/\/www.slideshare.net\/oom65\/hadoop-security-architecture?next_slideshow=1\n\n\nRef:\n\nhttps:\/\/community.hortonworks.com\/articles\/83100\/deep-learning-iot-workflows-with-raspberry-pi-mqtt.html\nhttps:\/\/community.hortonworks.com\/articles\/146704\/edge-analytics-with-nvidia-jetson-tx1-running-apac.html\nhttps:\/\/dzone.com\/refcardz\/introduction-to-tensorflow",
                "tags": "apachemxnet,apacheopennlp,apachetika,apachehive,apachehadoop,apachespark",
                "id": "7058e0d4f5ab28836",
                "pending": false,
                "bio": "Tim Spann has over a decade of experience with data and Java programming.   He has a BS and MS in Computer Science.   He has been a Senior Solutions Architect at AirisData working with Spark and Machine Learning. Before that he was a Senior Field Engineer for Pivotal. He blogs for DZone where he is the Big Data Zone Leader.  He runs a popular meetup in Princeton on Big Data and Spark.  He currently is a Solutions Engineer at Hortonworks working with Apache Spark, Big Data, IoT, Machine Learning and Deep Learning.\n\nhttps:\/\/dzone.com\/refcardz\/introduction-to-tensorflow\nhttp:\/\/www.meetup.com\/futureofdata-princeton\/\nhttps:\/\/community.hortonworks.com\/users\/9304\/tspann.html\nhttps:\/\/dzone.com\/users\/297029\/bunkertor.html",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "7058e0d4f5ab28836",
                "onhold": false,
                "title": "Apache Deep Learning 101",
                "speaker": "Timothy Spann",
                "conference": "apachecon-north-america-2018",
                "submitter": "640bd1885f7be91e37fe0579bee7c2f7195cb8fd",
                "level": 1,
                "accepted": true
              },
              "room": "3a98f01da63498d05",
              "day": 1538092800,
              "assignee": "7058e0d4f5ab28836",
              "title": "12:20 -> 13:10 (50 min)",
              "endtime": 1538140200
            },
            {
              "starttime": 1538145600,
              "origin": "3a98f01da63498d05",
              "id": "3a826fea256a3e8d9",
              "duration": 50,
              "readonly": false,
              "request_id": "3a826fea256a3e8d9",
              "talk": {
                "created": 1522430305,
                "notes": "",
                "description": "Presentations about data processing systems such as Spark, Flink and others typically concern their scalability, programming model and operational details. However, the design of abstractions for data ingestion (IO) is rarely discussed. This is unfortunate, considering that reading and writing data is a fundamental part of data processing. In this talk we intend to close the gap by describing Apache Beam's philosophy for developing IO connectors. Beam is a new programming model for unified and portable batch\/streaming data processing.\n\nWe will discuss how Beam's IO connectors approach correctness (e.g. fault tolerance, error handling) and performance (scalability, throughput, latency), and we will introduce a key element of Beam's IO philosophy - the idea that IO is no different from other data processing, and should be expressed via the same programming model primitives and be subject to the same ideals of modularity. This approach not only dramatically simplifies the implementation of IO connectors, but enables new dynamic patterns and APIs that otherwise would be cumbersome or impossible, e.g. reading data whose location is computed by the pipeline itself, sequencing streaming writes to multiple systems, general-purpose streaming of new results of a repeated query, etc. In some cases this approach requires a new programming model primitive, \"Splittable DoFn\", which we also discuss - however, in general  it is not specific to Beam and we encourage other data processing systems to adopt these ideas too.",
                "tags": "Apache Beam, Modularity, API, IO, connectors",
                "id": "9d56e79f3c681c967",
                "pending": false,
                "bio": "Ismaël Mejía is a software engineer with more than ten years of experience designing and developing information systems for financial groups, telecom companies and startups. Focused on Big Data and Cloud architectures (aka Distributed Systems). He works at Talend France as an Open Source Software Engineer. He is an Apache Beam committer and PMC member and an enthusiastic contributor to multiple open source projects.\n\nEugene Kirpichov is a staff software engineer on the Cloud Dataflow team at Google, where he works on the Apache Beam programming model and APIs. Previously, Eugene worked on Cloud Dataflow’s autoscaling and straggler elimination techniques. He is interested in programming language theory, data visualization, and machine learning.\n",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "9d56e79f3c681c967",
                "onhold": false,
                "title": "Robust, performant and modular APIs for data ingestion with Apache Beam",
                "speaker": "Ismaël Mejía, Eugene Kirpichov",
                "conference": "apachecon-north-america-2018",
                "submitter": "1e8baacf9daa0fe81312e298a0ddacf1374b59f4",
                "level": 1,
                "accepted": true
              },
              "room": "3a98f01da63498d05",
              "day": 1538092800,
              "assignee": "9d56e79f3c681c967",
              "title": "14:40 -> 15:30 (50 min)",
              "endtime": 1538148600
            },
            {
              "starttime": 1538149200,
              "origin": "3a98f01da63498d05",
              "id": "87b902ead47f58b80",
              "duration": 50,
              "readonly": false,
              "request_id": "87b902ead47f58b80",
              "talk": {
                "created": 1522454055,
                "notes": "",
                "description": "Apache Gobblin is a distributed data integration framework for both streaming and batch data ecosystems. In this talk, we will discuss how Gobblin powers several data processing pipelines at LinkedIn. We will dive into a few use-cases such as: ingestion of 300+ billion events for thousands of Kafka topics on a daily basis, metadata and storage management for several petabytes of data on HDFS, and near real-time processing of thousands of enterprise customer jobs. We will talk about the key Gobblin features that help us build and run these data pipelines at extreme scale, including: \n- Multiple execution modes: standalone, mapreduce, cluster (bare metal \/ Yarn), cloud (AWS \/ Azure) and embedded. \n- Powerful state management. \n- Write once, run anywhere jobs and rich connector library. \nWe will also explore the new and upcoming developments in Gobblin ecosystem such as Global Throttling, Gobblin on AWS, and Gobblin-as-a-Service. ",
                "tags": "Apache Gobblin, Apache Kafka, Apache Hadoop, Apache Helix, AWS, Azure, Yarn",
                "id": "e02c49a48d47a3a03",
                "pending": false,
                "bio": "Abhishek Tiwari is a Committer and PPMC member of Apache Gobblin (incubating). He is the Tech Lead for Data Integration Infrastructure at LinkedIn. Before joining LinkedIn, he had worked on building Amazon CloudSearch service at AWS, platform for Watson supercomputer at Nuance, Hadoop infrastructure at Yahoo, and web architecture for several million monthly users at AOL.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "onhold": false,
                "request_id": "e02c49a48d47a3a03",
                "title": "Apache Gobblin: Stream and Batch Data Integration at LinkedIn Scale",
                "speaker": "Abhishek Tiwari",
                "conference": "apachecon-north-america-2018",
                "submitter": "113d65ee2a3772afaf7c74755f6c0c9b754d5a1c",
                "level": 1,
                "accepted": true
              },
              "room": "3a98f01da63498d05",
              "day": 1538092800,
              "assignee": "e02c49a48d47a3a03",
              "title": "15:40 -> 16:30 (50 min)",
              "endtime": 1538152200
            },
            {
              "starttime": 1538152800,
              "origin": "3a98f01da63498d05",
              "id": "4499c33312bbc1b41",
              "duration": 50,
              "readonly": false,
              "request_id": "4499c33312bbc1b41",
              "talk": {
                "created": 1522450693,
                "notes": "",
                "description": "Large organizations have various data processing use cases from a diverse user base with different levels of understanding of the data infrastructure such as Hadoop and Spark. This often results in lengthy job debugging cycles, fragile job configurations, inefficient job executions, and other operational bottlenecks. Pinterest, with 200M+ users, heavily relies on data processing for product features and insights. Hundreds of analysts, data scientists and engineers run tens of thousands of jobs processing tens of petabytes everyday. In this presentation, we are going to discuss how Pinterest’s self-serve batch data processing evolved with various frameworks and tools that provide visibility on jobs and help users write efficient jobs and debug problems more easily.",
                "tags": "",
                "id": "557c2dd417fcb44de",
                "pending": false,
                "bio": "Jooseong is a software engineer at Pinterest in the Big Data Platform team. He has worked on various parts of the data engineering stack at Pinterest, and he focuses on batch data processing infrastructure. Prior to Pinterest, Jooseong was a software engineer at Oracle in the kernel service team, where he worked on database internals such as the cpu scheduler, the data warehouse parallel query scheduler, etc.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "557c2dd417fcb44de",
                "onhold": false,
                "title": "Scaling a self-serve big data platform service for a large organization",
                "speaker": "Jooseong Kim",
                "conference": "apachecon-north-america-2018",
                "submitter": "1dd048d1c852cdff56fe76352d91f3321efa2dba",
                "level": 1,
                "accepted": true
              },
              "room": "3a98f01da63498d05",
              "day": 1538092800,
              "assignee": "557c2dd417fcb44de",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1538155800
            }
          ]
        },
        {
          "day": 1538006400,
          "slots": [
            {
              "starttime": 1538043300,
              "origin": "3a98f01da63498d05",
              "id": "5c692ae1effed3de6",
              "duration": 50,
              "readonly": false,
              "request_id": "5c692ae1effed3de6",
              "talk": {
                "description": "The Open Geospatial Consortium (OGC) defines many international standards that make interoperability possible between different geospatial applications. Most standards are articulated around data formats (Well Known Text, Geographic Markup Language, etc.) and web services (Web Map Service, Web Feature Service, etc.) Those standards enable data transfers between server machines, where data are stored, and client machines, where data are typically processed (except with Web Processing Service). But in a world of petabytes of Earth Observation data, bringing data to the algorithm is not always practical; there is sometime a need to bring algorithm to data instead. Google Earth Engine, Open Data Cube, OpenEO and Amazon lambdas are examples of environments where data are hosted and computed remotely. In those environments, the OGC standards for data transfers do not apply as much as in the \"classical\" situation. Consequently each cloud environment defines its own, non-standard API for handling geospatial data.\n\nThis presentation will show how an old OGC effort — GeoAPI — could apply to the cloud environment for some kinds of problems. An example of remote execution using the same standard API in both Java and Python languages will be shown. We will present advantage and inconvenient of using a standard API. In particular the perceived complexity of international standards should be weighted against the problems of popular simple alternatives. Apache Spatial Information System (SIS) will be presented as a GeoAPI implementation with a focus on new features, some of them resulting from evolution in standards.\n\nThis talk is aimed to peoples having an interest in international standards applied to geospatial data, their implementation in Apache SIS, and how cloud environments may impact those standards. This talk will introduce some advanced features like dynamic datums in spatial referencing, but mainly as illustrations of the expertise contained in international standards.",
                "onhold": false,
                "bio": "I hold a Ph.D thesis in oceanography, but have continuously developed tools for helping analysis work. I used C\/C++ before to switch to Java in 1997. I develop geospatial libraries since that time, initially as a personal project then as a GeoTools contributor until 2008. I'm now contributing to Apache SIS since 2013. I attend to Open Geospatial Consortium (OGC) meetings about twice per year in the hope to follow closely standard developments and improve Apache SIS conformance to those standards. I work in a small IT services company (Geomatys) specialized in development of geoportals. Geomatys is an OGC member and develop a stack of open source software for spatial applications, with Apache SIS as the foundation to which Geomatys contributes actively.",
                "request_id": "0e9f93e752c101634",
                "category": "geospatial",
                "conference": "apachecon-north-america-2018",
                "level": 1,
                "created": 1522334983,
                "notes": "",
                "tags": "geospatial",
                "id": "0e9f93e752c101634",
                "pending": false,
                "accepted": true,
                "title": "Which geospatial API for the cloud?",
                "speaker": "Martin Desruisseaux",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "submitter": "4fb04977e5fc704cfe0ce73329a132899e834055"
              },
              "room": "3a98f01da63498d05",
              "day": 1538006400,
              "assignee": "0e9f93e752c101634",
              "title": "10:15 -> 11:05 (50 min)",
              "endtime": 1538046300
            },
            {
              "starttime": 1538046900,
              "origin": "3a98f01da63498d05",
              "id": "0a4af63eb706ad3fe",
              "duration": 50,
              "readonly": false,
              "request_id": "0a4af63eb706ad3fe",
              "talk": {
                "description": "The importance of handling GIS data in telecommunication industry is ever increasing, especially in OSS(Operation Support System) field. We, SK Telecom which is Korea’s number-one telecommunications provider, also has confronted the same problem. To get current status in time, we have been using Druid for years with many successes but it’s missing of native handling of gis data us keep old legacy systems, which is expensive and hard to expand.\n\nTo accommodate this, we have searched various softwares stacks and found Apache Lucene has enough capabilities in both aspects of function and performance. In this session, we will share how we have integrated two technology (Apache Druid and Apache Lucene) handling GIS data, and will provide use cases on them.",
                "onhold": false,
                "bio": "Jinchul Kim is a back-end software engineer with 12 years experience at databases and distributed systems. His focuses have been on query optimization, distributed data processing, scalable services and cloud computing systems. He currently works as a senior engineer for OLAP and MPP SQL engines development to accelerate telco. and semiconductor data analysis at SK Telecom. Before joining the current company, he worked at SAP as a SAP HANA engine developer for about 10 years.\n\nNavis is a Java developer, for 17 years (committer of Apache Hive and Druid).",
                "request_id": "9d31a2c8e70fc2435",
                "category": "geospatial",
                "conference": "apachecon-north-america-2018",
                "level": 0,
                "created": 1522382629,
                "notes": "",
                "tags": "GIS, Druid, Lucene",
                "id": "9d31a2c8e70fc2435",
                "pending": false,
                "accepted": true,
                "title": "Spatial index optimization using Lucene index and GIS query support",
                "speaker": "Jinchul Kim, Navis",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "submitter": "ba4915d724b43cc800f754a2a8deec56bb62b228"
              },
              "room": "3a98f01da63498d05",
              "day": 1538006400,
              "assignee": "9d31a2c8e70fc2435",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1538049900
            },
            {
              "starttime": 1538050500,
              "origin": "3a98f01da63498d05",
              "id": "b5de2604c15dad735",
              "duration": 50,
              "readonly": false,
              "request_id": "b5de2604c15dad735",
              "talk": {
                "description": "Spatial and GIS applications have traditionally required specialized databases, or at least specialized data structures like r-trees. Unfortunately this means that hybrid applications such as spatial analytics are not well served, and many people are unaware of the power of spatial queries because their favorite database does not support them.\n\nIn this talk, we describe how Apache Calcite enables efficient spatial queries using generic data structures such as HBase’s key-sorted tables, using techniques like Hilbert space-filling curves and materialized views. Calcite implements much of the OpenGIS function set and recognizes query patterns that can be rewritten to use particular spatial indexes. Calcite is bringing spatial query to the masses!",
                "onhold": false,
                "bio": "Julian Hyde is an expert in query optimization and in-memory analytics. He founded Apache Calcite, an engine for query optimization and data virtualization. He also founded Mondrian, the most popular open source OLAP engine. He is an architect at Looker.",
                "request_id": "476a7b072ff554ebc",
                "category": "geospatial",
                "conference": "apachecon-north-america-2018",
                "level": 2,
                "created": 1520478772,
                "notes": "",
                "tags": "spatial,sql,calcite,query optimization",
                "id": "476a7b072ff554ebc",
                "pending": false,
                "accepted": true,
                "title": "Spatial query on vanilla databases",
                "speaker": "Julian Hyde",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "submitter": "9e8f01fe45c56c67c69ee7e1dc538a8d43a643fc"
              },
              "room": "3a98f01da63498d05",
              "day": 1538006400,
              "assignee": "476a7b072ff554ebc",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1538053500
            },
            {
              "starttime": 1538058600,
              "origin": "3a98f01da63498d05",
              "id": "a01c4cce85cc7237f",
              "duration": 50,
              "readonly": false,
              "request_id": "a01c4cce85cc7237f",
              "talk": {
                "description": "The increasing availability of large-scale cloud computing resources has enabled large-scale environmental predictive models such as the National Water Model (NWM) to be run essentially continuously. Such models generate so many predictions that the output alone presents a big data computing challenge to interact with and learn from.\n\nResearchers at the Harvard Center for Geographic Analysis are working with the open-source, GPU-powered database MapD and Apache Kafka to provide true real-time, interactive access to NWM predictions for stream flow and ground saturation across the entire continental US and from present conditions to 18 days in the future. Predictions can be viewed prospectively, “how will conditions change going forward?” as well as retrospectively, “how did condition predictions evolve up to any given present?”. Water conditions can also be tracked in space and time together as storms move across the country.\n\nThe speed and flexibility of the GPU analytics platform allows questions such as “how did the stream flow prediction error change over time?\" to be answered quickly with SQL queries, and facilitates joining in additional data such as the location of bridges and other vulnerable infrastructure, all with relatively low-cost computing resources. MapD and other open-source high-performance geospatial computing tools have the potential to greatly broaden access to the full benefits of large-scale environmental models being deployed today.",
                "onhold": false,
                "bio": "Aaron is responsible for MapD’s developer, user and open source communities. He comes to MapD with more than two decades of previous success building ecosystems around some of software’s most familiar platforms. Most recently he ran the global community for Mesosphere, including leading the launch and growth of DC\/OS as an open source project. Prior to that he led the Java Community Process at Sun Microsystems, and ecosystem programs at SAP. Aaron has also served as the founding CEO of two startups in the entertainment space. Aaron has an MS in Computer Science and BS in Computer Engineering from Case Western Reserve University.\n\nBen is manager of Harvard WorldMap, an open source infrastructure to support collaborative research around geospatial information.  Ben is also leading a team to build a global registry of web map services (HHypermap) and another to develop a platform to support interactive exploration of billions of spatio-temporal things (BOP). Before joining Harvard Ben was a project manager with Advanced Technology Solutions of Pennsylvania (now GeographIT), where he led the company in adopting platform independent approaches to GIS system development. Ben studied Chinese at the University of Wisconsin and has a Masters in Planning from the University of Pennsylvania. After Penn, Ben worked at the U.C Berkeley GIS Lab, started the GIS group for the transportation engineering firm McCormick Taylor, and coordinated the Land Acquisition Mapping System for the South Florida Water Management District.",
                "request_id": "6b119c0de90192bbe",
                "category": "geospatial",
                "conference": "apachecon-north-america-2018",
                "level": 1,
                "created": 1522446275,
                "notes": "",
                "tags": "Big data, geospatial, kafka, GPU, predictive",
                "id": "6b119c0de90192bbe",
                "pending": false,
                "accepted": true,
                "title": "Interacting with Billions of National Water Model (NWM) Predictions using Apache Kafka and MapD",
                "speaker": "Aaron Williams, Ben Lewis",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "submitter": "fd0eb4b036d87ac37b775473e91968bb11e94daf"
              },
              "room": "3a98f01da63498d05",
              "day": 1538006400,
              "assignee": "6b119c0de90192bbe",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1538061600
            },
            {
              "starttime": 1538062200,
              "origin": "3a98f01da63498d05",
              "id": "0727a877dd681de70",
              "duration": 50,
              "readonly": false,
              "request_id": "0727a877dd681de70",
              "talk": {
                "description": "“Geospatial Track”\n\nMultiple Apache projects implement geospatial data structures and processing.  This presentation provides an overview of geospatial implementations across Apache projects. The presentation includes discussion of how open, consensus standards enable interoperability and interchangeability of open source software components. Highlights of open geospatial standards from the Open Geospatial Consortium (OGC) and other organizations is included.\n\nApache SIS provides data structures and methods for geographic features including coordinate reference systems, e.g., OGC WKT CRS2. Several projects are providing geospatial structures and methods for Apache Spark, e.g., how to apply Simple Features in Spark.  Several projects are addressing spatial indexes on gridded structures including building on Apache Projects and the related OGC DGGS.  Apache Science Data Analytics Platform (SDAP) enables fast analysis of oceanographic data.  A recent Location Powers workshop highlighted linked-geo-data building on Apache Projects.  \n\nOGC standards play an important role for data exchange, which is an area that is increasingly being addressed by the Apache community. For example running Spark on data stored in multiple Cassandra instances is facilitated by using geospatial data models provided by OGC standards. A similar advantage happens when publishing results after analysis.\n\nCoordination of geospatial topics increases data quality and reduces development effort. Coordination based on the use of open consensus standards provides stable and proven APIs and encodings for interoperability and interchangeability of software components. After a session at ApacheCon two years ago, a mailing list was established: geospatial@apache.org.  The presentation will conclude with an open discussion of geospatial projects across Apache.\n\n",
                "onhold": false,
                "bio": "George Percivall serves as the Chief Technology Officer (CTO) and Chief Engineer of the Open Geospatial Consortium (OGC).\n\nAs CTO he is responsible for working with OGC members to ensure a strategic technology focus across the OGC Programs in support of the strategic vision set forth by the OGC Board of Directors.  As lead technology architect for the Consortium he authorizes technical staff to propose and implement technology approaches across the Consortium.  As Chief Engineer, he promotes consistent and sound architectures including an emphasis on innovation and emerging technology.  He chairs the OGC Architecture Board and is an appointed member of the OGC Board of Directors.\n\nPrior to joining OGC, Mr. Percivall was Chief Engineer with Hughes Aircraft for NASA's Earth Observing System Data and Information System (EOSDIS) - Landsat\/Terra release; Principal engineer for NASA's Digital Earth Office; and represented NASA in OGC, ISO and CEOS. He was Director of the GST's Geospatial Interoperability Group. Previously, he led developments in Intelligent Transportation Systems with the US Automated Highway Consortium and General Motors Systems Engineering including the EV1 program. He began his career with Hughes as a Control System Engineer on GOES\/GMS satellites. He holds a BS in Engineering Physics and an MS in Electrical Engineering from the University of Illinois - Urbana.\n",
                "request_id": "cf7ac7ec54b4b7453",
                "category": "geospatial",
                "conference": "apachecon-north-america-2018",
                "level": 1,
                "created": 1522336053,
                "notes": "Geospatial Track",
                "tags": "geospatial",
                "id": "cf7ac7ec54b4b7453",
                "pending": false,
                "accepted": true,
                "title": "Geospatial data and processing in Apache projects",
                "speaker": "George Percivall, Ingo Simonis",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "submitter": "dcac2753669a9667951d72fea6655afe549bbbd7"
              },
              "room": "3a98f01da63498d05",
              "day": 1538006400,
              "assignee": "cf7ac7ec54b4b7453",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1538065200
            },
            {
              "starttime": 1538065800,
              "origin": "3a98f01da63498d05",
              "id": "612f4e11193434570",
              "duration": 50,
              "readonly": false,
              "request_id": "612f4e11193434570",
              "talk": {
                "created": 1524061092,
                "notes": "",
                "description": "Apache Spark has risen as one of the most important tool of big data analytics in a distributed computing environment. A relatively recent functionality, Deep Learning Pipeline, facilitates deep learning into the MLlib (Spark’s machine learning library) Pipelines API. We will show how this functionality opens opportunities for processing and analysing a large amount of images, in particular for images time series. As an example, we will demonstrate how a large historical set of satellite images, available through an open data cube, can be featurized through deep neural networks. The created features will be combined with records of flooding events in order to train MLlib’s algorithms to recognize flooding conditions. The resulting models could potentally provide flooding risk indicators.",
                "tags": "geospatial",
                "id": "17e9b91bbf67a692d",
                "pending": false,
                "bio": "Bio goes here. Bio goes here. Bio goes here. Bio goes here. Bio goes here. Bio goes here. Bio goes here. Bio goes here. Bio goes here. Bio goes here. Bio goes here. ",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "17e9b91bbf67a692d",
                "onhold": false,
                "title": "Geospatial Placeholder",
                "speaker": "Geospatial Speaker",
                "conference": "apachecon-north-america-2018",
                "submitter": "6e13ead734e1e92ba4ea121e5d8a67280d0f4614",
                "level": 0,
                "accepted": true
              },
              "room": "3a98f01da63498d05",
              "day": 1538006400,
              "assignee": "17e9b91bbf67a692d",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1538068800
            }
          ]
        },
        {
          "day": 1537833600,
          "slots": [
            {
              "starttime": 1537866000,
              "origin": "3a98f01da63498d05",
              "id": "e82b3925d896660ee",
              "duration": 50,
              "readonly": false,
              "request_id": "e82b3925d896660ee",
              "room": "3a98f01da63498d05",
              "day": 1537833600,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537869000
            },
            {
              "starttime": 1537869600,
              "origin": "3a98f01da63498d05",
              "id": "cec531b9561f3af56",
              "duration": 50,
              "readonly": false,
              "request_id": "cec531b9561f3af56",
              "room": "3a98f01da63498d05",
              "day": 1537833600,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537872600
            },
            {
              "starttime": 1537874400,
              "origin": "3a98f01da63498d05",
              "id": "760b2465d204c5c95",
              "duration": 50,
              "readonly": false,
              "request_id": "760b2465d204c5c95",
              "room": "3a98f01da63498d05",
              "day": 1537833600,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537877400
            },
            {
              "starttime": 1537878000,
              "origin": "3a98f01da63498d05",
              "id": "ec4f6072434e67cd7",
              "duration": 50,
              "readonly": false,
              "request_id": "ec4f6072434e67cd7",
              "room": "3a98f01da63498d05",
              "day": 1537833600,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537881000
            },
            {
              "starttime": 1537886400,
              "origin": "3a98f01da63498d05",
              "id": "0fd19548dcd1d42a4",
              "duration": 50,
              "readonly": false,
              "request_id": "0fd19548dcd1d42a4",
              "room": "3a98f01da63498d05",
              "day": 1537833600,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537889400
            },
            {
              "starttime": 1537890000,
              "origin": "3a98f01da63498d05",
              "id": "682d3f3465db0c17d",
              "duration": 50,
              "readonly": false,
              "request_id": "682d3f3465db0c17d",
              "room": "3a98f01da63498d05",
              "day": 1537833600,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537893000
            },
            {
              "starttime": 1537893600,
              "origin": "3a98f01da63498d05",
              "id": "4bded0a8bba9baae7",
              "duration": 40,
              "readonly": false,
              "request_id": "4bded0a8bba9baae7",
              "room": "3a98f01da63498d05",
              "day": 1537833600,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537896000
            },
            {
              "starttime": 1537896300,
              "origin": "3a98f01da63498d05",
              "id": "f2f0d8d632cf6076c",
              "duration": 35,
              "readonly": false,
              "request_id": "f2f0d8d632cf6076c",
              "room": "3a98f01da63498d05",
              "day": 1537833600,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537898400
            }
          ]
        }
      ]
    },
    {
      "id": "2b6f30dd151759cf3",
      "name": "Track2",
      "days": [
        {
          "day": 1537920000,
          "slots": [
            {
              "starttime": 1537959900,
              "origin": "2b6f30dd151759cf3",
              "id": "1b95767d65be46f64",
              "duration": 50,
              "readonly": false,
              "request_id": "1b95767d65be46f64",
              "talk": {
                "created": 1522163385,
                "notes": "I would prefer not to be filmed",
                "description": "Apache Beam provides a unified programming model to execute batch and streaming pipelines on all the popular big data engines. Lately it has gone beyond by also providing a unified way to supervise the pipeline execution: universal metrics. No matter what the chosen execution engine is, Apache Spark, Apache Flink or others, you specify the metrics to be collected with the same API and you extract them in a coherent way. \nIn this talk, you will discover the Beam metrics API, the integration with the runners and finally an end to end example.",
                "tags": "Big data, Beam, Metrics, Batch, Streaming, Pipeline, Supervision, Spark, Flink, Dataflow",
                "id": "e22bd89bacbe03a36",
                "pending": false,
                "bio": "Etienne has been working in software engineering and architecture for more than 13 years in domains such as retail or financial groups. He has been focusing on Big Data for some years on technologies such as Apache Cassandra, ElasticSearch, Apache Spark or Apache Beam. He is an Open Source fan and now works at Talend France where he contributes to Apache projects such as Apache Beam. He is a Beam committer.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "e22bd89bacbe03a36",
                "onhold": false,
                "title": "Universal metrics with Beam",
                "speaker": "Etienne Chauchot",
                "conference": "apachecon-north-america-2018",
                "submitter": "f61eb282b7ae499b8964fb44356677a8e250bcde",
                "level": 0,
                "accepted": true
              },
              "room": "2b6f30dd151759cf3",
              "day": 1537920000,
              "assignee": "e22bd89bacbe03a36",
              "title": "11:05 -> 11:55 (50 min)",
              "endtime": 1537962900
            },
            {
              "starttime": 1537963500,
              "origin": "2b6f30dd151759cf3",
              "id": "eac4a5dccbc681e40",
              "duration": 50,
              "readonly": false,
              "request_id": "eac4a5dccbc681e40",
              "talk": {
                "created": 1522442968,
                "notes": "",
                "description": "Many enterprises have a need to store their operational data in a NoSQL database and either pre-aggregated or raw data in a distributed file system such as HDFS. In such a heterogeneous architecture, it is imperative to have a unified query capability where data from one type of data source can be joined with data from another type in order to perform advanced analytics. At the same time, for performance reasons, it is crucial to leverage the underlying indexing and partitioning capabilities provided by each data source. \n \nIn this talk, I will describe how Apache Drill provides such a unified SQL querying capability over both NoSQL databases and files in a distributed file system. It achieves this through an innovative extensible architecture where the underlying data source exposes the artifacts, such as data locality and parallelization information, that are needed by the Drill query optimizer and executor. \n \nIn the case of a NoSQL database, Drill provides a comprehensive framework to expose the index metadata (if the system supports indexes) which are then used to generate index-based plans. While in the case of file systems, Drill supports partitioning of files within a single directory or hierarchy of directories. Filter pushdown and partitioning pruning optimizations are applied to reduce the amount of data read from disk. The talk will also discuss certain best practices about the data layout and data modeling that enable the above optimizations and substantially improve performance.\n",
                "tags": "",
                "id": "35bf3c3086ba08a52",
                "pending": false,
                "bio": "Aman Sinha is a Senior Principal Engineer at MapR, the PMC chair of Apache Drill and a PMC member of Apache Calcite. His work spans the areas of query processing and optimization in databases and big data systems.  He has previously worked at ParAccel (columnar, MPP database) and in the Business Intelligence group at IBM.  He has a Ph.D in Computer Engineering from The University of Texas at Austin. ",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "35bf3c3086ba08a52",
                "onhold": false,
                "title": "How Apache Drill enables fast analytics over NoSQL databases and distributed file system.",
                "speaker": "Aman Sinha",
                "conference": "apachecon-north-america-2018",
                "submitter": "825c58f8efacb32cc9f752749144e460771632f7",
                "level": 1,
                "accepted": true
              },
              "room": "2b6f30dd151759cf3",
              "day": 1537920000,
              "assignee": "35bf3c3086ba08a52",
              "title": "12:05 -> 12:55 (50 min)",
              "endtime": 1537966500
            },
            {
              "starttime": 1537972200,
              "origin": "2b6f30dd151759cf3",
              "id": "b17e5ebce9e6f02dd",
              "duration": 50,
              "readonly": false,
              "request_id": "b17e5ebce9e6f02dd",
              "talk": {
                "created": 1522420017,
                "notes": "",
                "description": "Apache Ranger is an authorization solution for Big Data projects at Apache. In this talk we will give an overview of the authorization challenges of Big Data projects, and how Apache Ranger can be used to solve these problems. The new features and capabilities of the 1.0.0 release will also be covered, as well as a guide to what's coming in future releases.",
                "tags": "Security, Big-Data",
                "id": "d8997ed578ac2d664",
                "pending": false,
                "bio": "Dr. Colm O hEigeartaigh is a senior security architect at Talend. He has previously spoken at a number of different ApacheCon North America and Europe events.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "d8997ed578ac2d664",
                "onhold": false,
                "title": "What's new in Apache Ranger 1.0.0",
                "speaker": "Colm O hEigeartaigh",
                "conference": "apachecon-north-america-2018",
                "submitter": "6d423ca70f79558b4c334b96bba5cfde6027b0f8",
                "level": 0,
                "accepted": true
              },
              "room": "2b6f30dd151759cf3",
              "day": 1537920000,
              "assignee": "d8997ed578ac2d664",
              "title": "14:30 -> 15:20 (50 min)",
              "endtime": 1537975200
            },
            {
              "starttime": 1537975800,
              "origin": "2b6f30dd151759cf3",
              "id": "26f434ee32aa84286",
              "duration": 50,
              "readonly": false,
              "request_id": "26f434ee32aa84286",
              "talk": {
                "created": 1522354334,
                "notes": "Please provide a 3.5mm stereo audio hookup for my laptop, my presentations almost always have audio clips I need the audience to hear.",
                "description": "Much has changed for Apache CouchDB since 2013, when the previous talk of this title was given. With clustering, advanced querying, overhauled replication, search\/geo addons and more, CouchDB is a lot more capable than ever -- which means it's also a lot more misunderstood. Come to this talk to learn more about the ways people tend to misuse CouchDB, and intelligent ways to work better with it.\n\nAppropriate for all levels of experience - from those who haven't even heard of CouchDB, to those who use it daily.",
                "tags": "couchdb",
                "id": "2687c8318a7c550bb",
                "pending": false,
                "bio": "Joan Touzet is an ASF Member, Apache CouchDB PMC member and committer, with over 30 years of experience in commercial and open source software development. Based in Toronto, Canada, she currently works with Neighbourhoodie Software, running the CouchDB Development\/Production Support team. In her spare time, Joan composes and records music, rides motorcycles, designs and builds electronic musical instruments, and pets cats. Gnomes over ponies.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "2687c8318a7c550bb",
                "onhold": false,
                "title": "Another 10 Common Misconceptions about Apache CouchDB",
                "speaker": "Joan Touzet",
                "conference": "apachecon-north-america-2018",
                "submitter": "9f36cd23bbc29965d458f52130c9cd7dc2034b10",
                "level": 0,
                "accepted": true
              },
              "room": "2b6f30dd151759cf3",
              "day": 1537920000,
              "assignee": "2687c8318a7c550bb",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537978800
            },
            {
              "starttime": 1537980000,
              "origin": "2b6f30dd151759cf3",
              "id": "011d41f3bba00d9a8",
              "duration": 50,
              "readonly": false,
              "request_id": "011d41f3bba00d9a8",
              "talk": {
                "created": 1522409669,
                "notes": "",
                "description": "This talk briefly works through how to store and query wiki data on graph database, Apache S2Graph(incubating) using GraphQL. The talk breaks down to two part, the first one is how to load wiki data RDF dump into S2Graph to build knowledge graph, and the second part is how GraphQL implemented in S2Graph play nicely with knowledge graph as data API. Not only people who are interested in graph database but also people who want to know how to provide unified data API on complex data can benefit from this talk.",
                "tags": "GraphQL, Graph Database",
                "id": "9de4c36748e9848a1",
                "pending": false,
                "bio": "Doyung leads a data infrastructure team at Kakao, where his focus is on performance and usability. He developed Apache S2Graph, an open-source distributed graph database, and has previously presented it at ApacheCon BigData Europe and ApacheCon BigData North America.\t",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "onhold": false,
                "request_id": "9de4c36748e9848a1",
                "title": "GraphQL meets Apache S2Graph(incubating): Build Knowledge Graph and real-time data API",
                "speaker": "Doyung Yoon",
                "conference": "apachecon-north-america-2018",
                "submitter": "2fdf5080804c17d8e73596a70302f7de67488707",
                "level": 0,
                "accepted": true
              },
              "room": "2b6f30dd151759cf3",
              "day": 1537920000,
              "assignee": "9de4c36748e9848a1",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537983000
            }
          ]
        },
        {
          "day": 1538092800,
          "slots": [
            {
              "starttime": 1538125200,
              "origin": "2b6f30dd151759cf3",
              "id": "95f796ac3ba7d4e39",
              "duration": 50,
              "readonly": false,
              "request_id": "95f796ac3ba7d4e39",
              "talk": {
                "created": 1518537545,
                "notes": "",
                "description": "A review of the last 12 months in the Apache Tomcat project covering notable security vulnerabilities, critical bugs and significant new features followed by a look-ahead to the next 12 months including plans for Tomcat 10, products reaching end-of-life and thoughts on the impact of the transfer of JavaEE to Eclipse. This session is intended for anyone working with, or considering working with, Apache Tomcat and will provide an opportunity to learn more about the future roadmap.",
                "tags": "Tomcat, Java",
                "id": "2bc75a23afd2a5361",
                "pending": false,
                "bio": "I have been an Apache Tomcat committer since November 2003. I initially worked on Tomcat in my free time but since August 2008 I have been employed by SpringSource (now part of Pivotal) to work on Apache Tomcat. I spend most of my time working on Tomcat but I also work on tc Server, Pivotal's Servlet & JSP container based on Apache Tomcat.\n\nI am the release manager Apache Tomcat 8.5 and 9 where I try to release a new version every month or so. I am currently focused on Tomcat 9 development which supports Servlet 4.0. I was a member of the JCP expert group for JSR 369.\n\nElsewhere at the ASF, I am a member of the ASF security and infrastructure teams and I am also on the Commons PMC where I focus on Commons Pool and DBCP.\n\nI am a member of the ASF and have served as a Director since 2016.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "2bc75a23afd2a5361",
                "onhold": false,
                "title": "State of the Cat",
                "speaker": "Mark Thomas",
                "conference": "apachecon-north-america-2018",
                "submitter": "0388d3fc69207c2de0aa57213a7070c35bc775dc",
                "level": 0,
                "accepted": true
              },
              "room": "2b6f30dd151759cf3",
              "day": 1538092800,
              "assignee": "2bc75a23afd2a5361",
              "title": "09:00 -> 09:50 (50 min)",
              "endtime": 1538128200
            },
            {
              "starttime": 1538128800,
              "origin": "2b6f30dd151759cf3",
              "id": "5a6f571cd6891724d",
              "duration": 50,
              "readonly": false,
              "request_id": "5a6f571cd6891724d",
              "talk": {
                "created": 1519072349,
                "notes": "",
                "description": "Although mostly known as a fast and reliable web server, Apache httpd also excels as a reverse proxy. In this session find out how to setup httpd as a reverse proxy, how to connect to Tomcat using HTTP and AJP, and the full feature list of Apache httpd proxying capability.",
                "tags": "",
                "id": "40453b4e98ab6ecef",
                "pending": false,
                "bio": "Jim Jagielski is a well known and acknowledged expert and visionary in Open Source, an accomplished coder, and frequent engaging presenter on all things Open, Web and Cloud related. As a developer, he’s made substantial code contributions to just about every core technology behind the Internet and Web and in 2012 was awarded the O’Reilly Open Source Award and in 2015 received the Innovation Luminary Award from the EU. He is likely best known as one of the developers and co-founders of the Apache Software Foundation, where he has previously served as both Chairman and President and where he’s been on the Board Of Directors since day one. Currently he is Vice-Chairman. He’s served as President of the Outercurve Foundation and was also a director of the Open Source Initiative (OSI). Up until recently, he worked at Capital One as a Sr. Director in the Tech Fellows program. He credits his wife Eileen in keeping him sane.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "40453b4e98ab6ecef",
                "onhold": false,
                "title": "Apache httpd reverse proxy and Tomcat",
                "speaker": "Jim Jagielski",
                "conference": "apachecon-north-america-2018",
                "submitter": "48337cfe5eda963e4ac084b5e3c663a3e143926a",
                "level": 2,
                "accepted": true
              },
              "room": "2b6f30dd151759cf3",
              "day": 1538092800,
              "assignee": "40453b4e98ab6ecef",
              "title": "10:00 -> 10:50 (50 min)",
              "endtime": 1538131800
            },
            {
              "starttime": 1538133600,
              "origin": "2b6f30dd151759cf3",
              "id": "eb63bf20f4a6b6e1c",
              "duration": 50,
              "readonly": false,
              "request_id": "eb63bf20f4a6b6e1c",
              "talk": {
                "created": 1522236694,
                "notes": "",
                "description": "This presentation details the features that were recently added in Apache Tomcat 8.5 and 9, or that are considered for inclusion in future versions. Each feature is detailed with its benefits, possible future work remaining, caveats if any, and how to take advantage of it. The presentation covers HTTP\/2, NIO2, OpenSSL and others.",
                "tags": "tomcat",
                "id": "a197d5f8bcb16de2a",
                "pending": false,
                "bio": "Jean-Frederic has spent more than 20 years writing client\/server software. His knowledges range from Cobol to Java, BS2000 to Linux and \/390 to i386 but with preference to the later ;). He is committer inHttpd and Tomcat and he likes complex projects where different languages and machines are involved. Borne in France, Jean-Frederic lived in Barcelona (Spain) for 14 years. Since May 2006 he lives in Neuchatel (Switzerland) where he works for RedHat in the JBoss division on Tomcat, httpd, CXF and cloud\/cluster related topics",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "a197d5f8bcb16de2a",
                "onhold": false,
                "title": "New and upcoming in Tomcat",
                "speaker": "Jean-Frederic Clere",
                "conference": "apachecon-north-america-2018",
                "submitter": "ea77ef0d4c3b3e953f74b2250e02343ac08e8d6c",
                "level": 1,
                "accepted": true
              },
              "room": "2b6f30dd151759cf3",
              "day": 1538092800,
              "assignee": "a197d5f8bcb16de2a",
              "title": "11:20 -> 12:10 (50 min)",
              "endtime": 1538136600
            },
            {
              "starttime": 1538137200,
              "origin": "2b6f30dd151759cf3",
              "id": "6ad07f44904bc1e1f",
              "duration": 50,
              "readonly": false,
              "request_id": "6ad07f44904bc1e1f",
              "talk": {
                "created": 1518511024,
                "notes": "",
                "description": "This talk with give and overview of exciting two releases for Apache HBase and Phoenix. HBase 2.0 is the next stable major release for Apache HBase scheduled for early 2018. It is the next evolution from the Apache HBase community after 1.0. HBase-2.0 contains a large number of features that is long time in the development, some of which include rewritten region assignment , perf improvements (RPC, rewritten write pipeline, etc), async clients and WAL, C++ client, offheaping memstore and other buffers,  shading of dependencies as well as a lot of other fixes and stability improvements. We will go into technical details on some of the most important improvements in the release, as well as what are the implications for the users in terms of API and upgrade paths. Phoenix 5.0 is the next biggest release because of it's integration with HBase-2.0 and lot of performance improvements in support of secondary Indexes. It has lot of cool features such as Encoded columns, Kafka, Hive integration, and many other performance improvements.\n",
                "tags": "hbase,phoenix,phoenix-spark,datawareshouse, nosql",
                "id": "809b46104600b6afe",
                "pending": false,
                "bio": "Ankit Singhal is a committer and a member of Apache Phoenix PMC (Project Managment Committee) for more than 2 years now. He has also been contributing to projects like HBase, Tephra, Calcite . He specializes in designing and developing big data solutions for different line of business. With over 7 years of Big Data experience, he has architected and created various analytics products and data warehouse solutions using Hadoop technologies like Hadoop, Kafka, Hive, HBase, Phoenix, spark. ",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "809b46104600b6afe",
                "onhold": false,
                "title": "Meet Apache HBase 2.0 and Phoenix 5.0",
                "speaker": "Ankit Singhal",
                "conference": "apachecon-north-america-2018",
                "submitter": "44712a763bcfd063161c12f578b7cfb0e3f8c11c",
                "level": 1,
                "accepted": true
              },
              "room": "2b6f30dd151759cf3",
              "day": 1538092800,
              "assignee": "809b46104600b6afe",
              "title": "12:20 -> 13:10 (50 min)",
              "endtime": 1538140200
            },
            {
              "starttime": 1538145600,
              "origin": "2b6f30dd151759cf3",
              "id": "68bda544f17577a67",
              "duration": 50,
              "readonly": false,
              "request_id": "68bda544f17577a67",
              "talk": {
                "created": 1522419839,
                "notes": "",
                "description": "Although over 20 years old, the Apache web server has kept pace with the times. Yet there is still confusion and misinformation about httpd and its capabilities. Learn the truth about  Apache httpd from its performance to its reverse proxy functionality and how it can hold its own as compared to all other web-servers.",
                "tags": "",
                "id": "7904c9361dd2286ad",
                "pending": false,
                "bio": "im Jagielski is a well known and acknowledged expert and visionary in Open Source, an accomplished coder, and frequent engaging presenter on all things Open, Web and Cloud related. As a developer, he’s made substantial code contributions to just about every core technology behind the Internet and Web and in 2012 was awarded the O’Reilly Open Source Award and in 2015 received the Innovation Luminary Award from the EU. He is likely best known as one of the developers and co-founders of the Apache Software Foundation, where he has previously served as both Chairman and President and where he’s been on the Board Of Directors since day one. Currently he is Vice-Chairman. He’s served as President of the Outercurve Foundation and was also a director of the Open Source Initiative (OSI). Up until recently, he worked at Capital One as a Sr. Director in the Tech Fellows program. He credits his wife Eileen in keeping him sane.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "7904c9361dd2286ad",
                "onhold": false,
                "title": "It Aint' Your Daddy's Web Server",
                "speaker": "Jim Jagielski",
                "conference": "apachecon-north-america-2018",
                "submitter": "48337cfe5eda963e4ac084b5e3c663a3e143926a",
                "level": 1,
                "accepted": true
              },
              "room": "2b6f30dd151759cf3",
              "day": 1538092800,
              "assignee": "7904c9361dd2286ad",
              "title": "14:40 -> 15:30 (50 min)",
              "endtime": 1538148600
            },
            {
              "starttime": 1538149200,
              "origin": "2b6f30dd151759cf3",
              "id": "bba072883b5134364",
              "duration": 50,
              "readonly": false,
              "request_id": "bba072883b5134364",
              "talk": {
                "created": 1519926932,
                "notes": "Here are slides for a past version of my presentation: https:\/\/speakerdeck.com\/sullis\/apache-struts-and-the-equifax-data-breach\n\nIf accepted, I plan to update\/adapt my slides for ApacheCon.",
                "description": "In September 2017, Equifax announced a major security breach. The breach may have exposed sensitive data for over 100 million US consumers. The breach was due, in part, to a vulnerability in an older release of Apache Struts 2.x\n\nThis talk will examine the vulnerabilities from the Apache Struts framework. We will review the underlying Java code and discuss the fixes that were applied by the Apache Struts team.",
                "tags": "java,web,struts,security",
                "id": "1dea3b994c37f9168",
                "pending": false,
                "bio": "Sean Sullivan is a Principal Software Engineer at the Hudson Bay Company. HBC owns and operates multiple retail businesses, including Saks Fifth Avenue, Lord & Taylor, and Gilt.com. Sean has contributed code to the AWS SDK for Java project on Github. He lives in Portland Oregon.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "1dea3b994c37f9168",
                "onhold": false,
                "title": "Apache Struts and the Equifax data breach",
                "speaker": "Sean Sullivan",
                "conference": "apachecon-north-america-2018",
                "submitter": "36058c5ea45866e3bb995dcc9f1b13af183d1789",
                "level": 1,
                "accepted": true
              },
              "room": "2b6f30dd151759cf3",
              "day": 1538092800,
              "assignee": "1dea3b994c37f9168",
              "title": "15:40 -> 16:30 (50 min)",
              "endtime": 1538152200
            },
            {
              "starttime": 1538152800,
              "origin": "2b6f30dd151759cf3",
              "id": "a87a108878c219a2d",
              "duration": 50,
              "readonly": false,
              "request_id": "a87a108878c219a2d",
              "talk": {
                "created": 1522439547,
                "notes": "",
                "description": "Apache Traffic Control allows you to build a large scale content delivery network using open source.  Built around Apache Traffic Server as the caching software, Traffic Control implements all the core functions of a modern CDN. Assembling these components into a cohesive network can be a daunting task.  We will demonstrate use of containers to get one up and running.\n\nThis talk will walk through the details of Traffic Control, describe its major components, how they interact, as well as provide a demo for each component and how they relate within running in a set of containers.\n",
                "tags": "CDN Containers",
                "id": "65681ec1b24a66eae",
                "pending": false,
                "bio": "Dewayne Richardson is a Principal Engineer with Comcast who has been a committer on the Traffic Control project since inception in 2015.  He has built systems in many programming languages and Go is the latest language he is learning to master.  Dewayne resides in Denver, CO with his family that keeps him on his toes.\n\nDan Kirkwood is a Senior Engineer with Comcast and also a committer on the Traffic Control project since 2015.  He has expertise in a number of programming languages including Perl and Go.  Dan lives in Denver, CO with his wife and two Portuguese Water Dogs.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "onhold": false,
                "request_id": "65681ec1b24a66eae",
                "title": "Apache Traffic Control Up and Running",
                "speaker": "Dewayne Richardson, Dan Kirkwood",
                "conference": "apachecon-north-america-2018",
                "submitter": "d4e7e71c8b99e17a49ee0e1d8dd4d3e4016ba74f",
                "level": 0,
                "accepted": true
              },
              "room": "2b6f30dd151759cf3",
              "day": 1538092800,
              "assignee": "65681ec1b24a66eae",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1538155800
            }
          ]
        },
        {
          "day": 1538006400,
          "slots": [
            {
              "starttime": 1538043300,
              "origin": "2b6f30dd151759cf3",
              "id": "2d0bad6f1c71a1fd8",
              "duration": 50,
              "readonly": false,
              "request_id": "2d0bad6f1c71a1fd8",
              "talk": {
                "created": 1522387800,
                "notes": "",
                "description": "In this talk, we will start from the very beginning of building out this Big Data platform at Uber. We will look at how the data stack evolves to chase the explosive growth in the last few years, and inspect the latest overall architecture and service offerings. We will explore how Apache Spark serve as a part of the machine learning platform and go through a few examples of intelligent systems built with it.\n\nSpecifically we will examine the role Apache Spark play throughout the years, where the internal community is seeded and flourished, and how we juggle a large number of internal projects along with a fast-paced, rapidly evolving open source community.\n\nFinally, we will analyze a few unique challenges with reliability, resource utilization, observability with Apache Spark at this volume and scale, and share our experience and lessons learned building our data platform with it and Apache Hadoop, Apache Mesos, Apache Kafka, Apache Parquet and a few others, at this enormous scale. We will detail the best practices developing, testing, validating, and deploying to production in a multi-data-center environment.\n",
                "tags": "bigdata, spark, machinelearning",
                "id": "728e1e07b4aec99a7",
                "pending": false,
                "bio": "Felix started in the big data space about 5 years ago with the then state-of-the-art MapReduce. Since then, he (re-)built Hadoop cluster from metal more times than he would like, created a Hadoop \"distro\" from two dozens or so projects, and kicked off clusters in the cloud with hundreds of cores on-demand. He built a few interesting app with Apache Spark for 3.5 years and ended up contributing to it for more than 3 years, and became a Committer & PMC along the way. In addition to building stuff, he frequently presented in conferences, meetups, or workshops.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "728e1e07b4aec99a7",
                "onhold": false,
                "title": "Scaling Apache Spark for data pipelines and intelligent systems at Uber",
                "speaker": "Felix Cheung",
                "conference": "apachecon-north-america-2018",
                "submitter": "5b0e1bfb0d5da24e7e7f0f579f5e6a9a38e85f62",
                "level": 1,
                "accepted": true
              },
              "room": "2b6f30dd151759cf3",
              "day": 1538006400,
              "assignee": "728e1e07b4aec99a7",
              "title": "10:15 -> 11:05 (50 min)",
              "endtime": 1538046300
            },
            {
              "starttime": 1538046900,
              "origin": "2b6f30dd151759cf3",
              "id": "13805b93af6d168fa",
              "duration": 50,
              "readonly": false,
              "request_id": "13805b93af6d168fa",
              "talk": {
                "created": 1522124687,
                "notes": "",
                "description": "For 5G, the equipment that requires control from the telecom company will increase exponentially. In recent years, we have performed big data-based processing and analysis to operate and stabilize our telecom equipment efficiently. Detailed analytics, for instance, RCA(Root Cause Analysis) requires the handling and storage of large amounts of data. In this session, we will explain and demonstrate data collection, processing and storage for control of large telecom operation, and forecasting through AI-based analysis. In particular, you will learn the following:\n- Apache Spark - real-time streaming and analysis\n- Apache Hbase - stores and processes data",
                "tags": "bigdata,spark,hbase,analytics,telco",
                "id": "2029028a18afbac2e",
                "pending": false,
                "bio": "Yousun Jeong is an IT manager of SK Telecom(SKT), South Korea’s largest wireless communications provider. She is also an Apache committer and applying Spark & Hbase on the company's big data analytics cluster. Big data analysis of SKT mainly focuses on the supports various data type, and it essentially needs real-time processing and real-time analysis for the AI-based network equipment & service monitoring platform. She is really hoping to share her experience with the conference attendees.\nJongHyok Lee is an architect of SK Telecom. With over 20 years of experience in data processing and management area, he is leading development of SK Telecom's datacenter and mobile network monitoring and analytics platform engine. Before joining SK Telecom, he worked at IBM as a certified senior architect and led number of data projects including data marts\/warehouses, master data managements, real-time data processing, and forecasting\/optimization in various industry.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "onhold": false,
                "request_id": "2029028a18afbac2e",
                "title": "Apache Spark & Apache Hbase :Apache Spark & Apache Hbase : AI-based Monitoring System In Big Telco",
                "speaker": "Yousun Jeong, JongHyok Lee",
                "conference": "apachecon-north-america-2018",
                "submitter": "d380fd66d59c4272cb9d1f37ed55e07d85ac43ed",
                "level": 0,
                "accepted": true
              },
              "room": "2b6f30dd151759cf3",
              "day": 1538006400,
              "assignee": "2029028a18afbac2e",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1538049900
            },
            {
              "starttime": 1538050500,
              "origin": "2b6f30dd151759cf3",
              "id": "90e94f5017b3c849e",
              "duration": 50,
              "readonly": false,
              "request_id": "90e94f5017b3c849e",
              "talk": {
                "created": 1518036472,
                "notes": "",
                "description": "Deep Learning has become ubiquitous with abundance of data, commoditization of compute and storage. Pre-trained models are readily available for many use-cases.  Distributed Inference has many applications such as pre-computing results offline, backfilling historic data with predictions from state-of-the-art models, etc.,. Inference on large scale datasets comes with many challenges prevalent in distributed data processing. Attendees will learn how to efficiently run deep learning prediction on large data sets, leveraging Apache Spark and Apache MXNet (incubating).\nOverview\n* Basic Deep Learning Concepts.\n1) Types of Learning,  \na) Supervised Learning\nb) Unsupervised Learning\nc) Active Learning\nd) Reinforcement Learning\n2) Supervised Learning types - classification, regression, Image classification,\n3) Types of Neural Networks - Feed forward Networks, CNNs, RNNs, GANs\n* Apache MXNet(Incubating) Deep Learning Framework.\nMXNet concepts ie., NDArray, Symbolic APIs and Module APIs.\nMXNet Gluon APIs\n* Distributed Inference using Apache MXNet and Apache Spark on Amazon EMR.\nIn this section, I will cover some of the use-cases of Distributed Inference, the challenges associated with running distributed Inference. \nFinally show how to leverage MXNet and Spark to run distributed inference on large-scale datasets on a publicly available dataset.",
                "tags": "",
                "id": "fe148d1923ebb0152",
                "pending": false,
                "bio": "Naveen is a Software Developer at AWS experienced in building large scale distributed systems. His focus now is to make Deep Learning easily accessible to the largest population of intellectuals - Engineers, without the need to become an expert at it.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "fe148d1923ebb0152",
                "onhold": false,
                "title": "Distributed Inference using Apache MXNet and Apache Spark",
                "speaker": "Naveen Swamy",
                "conference": "apachecon-north-america-2018",
                "submitter": "f82cf9d6de0c414e2dfede3e7411e36b459ba738",
                "level": 0,
                "accepted": true
              },
              "room": "2b6f30dd151759cf3",
              "day": 1538006400,
              "assignee": "fe148d1923ebb0152",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1538053500
            },
            {
              "starttime": 1538058600,
              "origin": "2b6f30dd151759cf3",
              "id": "9deeb3bb024a47e7a",
              "duration": 50,
              "readonly": false,
              "request_id": "9deeb3bb024a47e7a",
              "talk": {
                "created": 1519382923,
                "notes": "",
                "description": "The rapidly expanding world of stream processing can be daunting, with new concepts such as various types of time semantics, windowed aggregates, changelogs, and programming frameworks to master. KSQL is an open-source, Apache 2.0 licensed streaming SQL engine on top of Apache Kafka which aims to simplify all this and make stream processing available to everyone.\n\nKSQL makes it easy to read, write, and process streaming data in real-time, at scale, using SQL-like semantics. It offers an easy way to express stream processing logic as an alternative to writing an application in a programming language such as Java, Python or Go. Benefits of using KSQL include: No coding required; no additional analytics cluster needed; streams and tables as first-class constructs; access to the rich Kafka ecosystem.\n\nThis session introduces the concepts and architecture of KSQL. Use cases such as Streaming ETL, Real Time Stream Monitoring or Anomaly Detection are discussed. A live demo shows how to setup and use KSQL quickly and easily on top of your Kafka ecosystem.\n",
                "tags": "Kafka, KSQL",
                "id": "70dd2d8d3da3916d9",
                "pending": false,
                "bio": "Kai Waehner works as Technology Evangelist at Confluent. Kai’s main area of expertise lies within the fields of Big Data Analytics, Machine Learning \/ Deep Learning, Messaging, Integration, Microservices, Stream Processing, Internet of Things and Blockchain. He is regular speaker at international conferences such as JavaOne, O’Reilly Software Architecture or ApacheCon, writes articles for professional journals, and shares his experiences with new technologies on his blog (www.kai-waehner.de\/blog). Contact and references: kontakt@kai-waehner.de \/ @KaiWaehner \/ www.kai-waehner.de\n",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "70dd2d8d3da3916d9",
                "onhold": false,
                "title": "KSQL – An Open Source SQL Streaming Engine for Apache Kafka",
                "speaker": "Kai Wähner",
                "conference": "apachecon-north-america-2018",
                "submitter": "79836955c30623ea0d7c3afb5ccd703090fb76c4",
                "level": 0,
                "accepted": true
              },
              "room": "2b6f30dd151759cf3",
              "day": 1538006400,
              "assignee": "70dd2d8d3da3916d9",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1538061600
            },
            {
              "starttime": 1538062200,
              "origin": "2b6f30dd151759cf3",
              "id": "f8be7a41e6dcbb23d",
              "duration": 50,
              "readonly": false,
              "request_id": "f8be7a41e6dcbb23d",
              "talk": {
                "created": 1519790618,
                "notes": "",
                "description": "Apache Spark has become the tool of choice for data engineers and data scientists for data discovery, data munging and pipelining, general ETL and many other kinds of scalable distributed data processing tasks. One of the key contributing factor for this success is the consistent and easy to use distributed framework supporting Scala, Java, Python and R and the ability to connect Spark to a variety of data sources. Some connectors come bundled with Spark while some are available as part of the ecosystem from other projects and vendors. However there is often a need to integrate Spark with a source, destination or system for which there is no available connector.\n\nThis presentation is geared to address that problem by providing an under-the-hood understanding of batch and structured streaming sources and sinks in Spark. Furthermore, attendees will be able to develop their own custom data sources and sinks as well as be able to understand and appreciate the source code and optimally use existing data connectors and integrations like that for Kafka.",
                "tags": "Spark streaming data sources sinks structured streaming connectors integration",
                "id": "4d793cee3ff20f235",
                "pending": false,
                "bio": "Jayesh Thakrar is a senior software engineer at Conversant where he enjoys building, tinkering and fixing big data systems like Hadoop, HBase, Spark, Cassandra, Ambari, Flume, Kafka, Spark, OpenTSDB. Examples of \"big data\" volume include (1) processing 300+ billion log line data a day through a single Kafka cluster (2) supporting 500k+ requests\/sec from a single HBase cluster (3) and pushing 500+ million metrics daily into OpenTSDB. Jayesh likes to learn and share at meetups and conferences and has been a speaker at the past 2 Apache North America conferences.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "onhold": false,
                "request_id": "4d793cee3ff20f235",
                "title": "Under-the-Hood: Apache Spark Data Sources and Sinks",
                "speaker": "Jayesh Thakrar",
                "conference": "apachecon-north-america-2018",
                "submitter": "ed216643630fd3e1db39be808d9ec91aee2d2667",
                "level": 1,
                "accepted": true
              },
              "room": "2b6f30dd151759cf3",
              "day": 1538006400,
              "assignee": "4d793cee3ff20f235",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1538065200
            },
            {
              "starttime": 1538065800,
              "origin": "2b6f30dd151759cf3",
              "id": "7a49b3927c1e4a0a8",
              "duration": 50,
              "readonly": false,
              "request_id": "7a49b3927c1e4a0a8",
              "talk": {
                "created": 1521020498,
                "notes": "",
                "description": "Apache Hivemall is a scalable machine learning library for Apache Hive, Apache Spark, and Apache Pig. \nHivemall provides a number of machine learning functionalities across classification, regression, ensemble learning, and feature engineering through UDFs\/UDAFs\/UDTFs of Hive.\n\nWe have released the first Apache release (v0.5.0-incubating) on Mar 5, 2018 and the project plans to release v0.5.2 in Q2, 2018.\n\nWe will first give a quick walk-through of features, usages, what's new in v0.5.0, and future roadmaps of Apache Hivemall. Next, we will introduce Hivemall on Apache Spark in depth such as DataFrame integration and Spark 2.3 supports in Hivemall.",
                "tags": "machine learning, hadoop, spark, hive, sql",
                "id": "0cbf85b79b554dee6",
                "pending": false,
                "bio": "Makoto YUI is a Research Engineer of a Hadoop-as-a-Service startup, Treasure Data, Inc. He is leading the development of Apache Hivemall, an open source library for scalable machine learning on Apache Hive, Apache Spark, and Apache Pig. He holds a PhD degree in computer science from NAIST. Find his profile on http:\/\/myui.github.io\/\n\nTakeshi Yamamuro is a Research Engineer of NTT, a telecommunication company in Japan, working on Database backends and SIMD\/GPU-aware algorithms. He is a PPMC member of Hivemall. He worked on porting Hivemall functions to Apache Spark and developing a Parameter Mixing module that runs on Apache Hadoop Yarn. Find him on https:\/\/github.com\/maropu\/",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "onhold": false,
                "request_id": "0cbf85b79b554dee6",
                "title": "Introduction to Apache Hivemall v0.5.0: Machine Learning on Hive\/Spark",
                "speaker": "Makoto Yui, Takeshi Yamamuro",
                "conference": "apachecon-north-america-2018",
                "submitter": "26438d7fb56c945a82883c81dee734e71c11ba47",
                "level": 0,
                "accepted": true
              },
              "room": "2b6f30dd151759cf3",
              "day": 1538006400,
              "assignee": "0cbf85b79b554dee6",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1538068800
            }
          ]
        },
        {
          "day": 1537833600,
          "slots": [
            {
              "starttime": 1537869600,
              "origin": "2b6f30dd151759cf3",
              "id": "8792ff91b2b02ed4d",
              "duration": 50,
              "readonly": false,
              "request_id": "8792ff91b2b02ed4d",
              "room": "2b6f30dd151759cf3",
              "day": 1537833600,
              "assignee": null,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537872600
            },
            {
              "starttime": 1537874400,
              "origin": "2b6f30dd151759cf3",
              "id": "835eba80a1e3b1ec5",
              "duration": 50,
              "readonly": false,
              "request_id": "835eba80a1e3b1ec5",
              "room": "2b6f30dd151759cf3",
              "day": 1537833600,
              "assignee": null,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537877400
            },
            {
              "starttime": 1537878000,
              "origin": "2b6f30dd151759cf3",
              "id": "77c9c5a324478c021",
              "duration": 50,
              "readonly": false,
              "request_id": "77c9c5a324478c021",
              "room": "2b6f30dd151759cf3",
              "day": 1537833600,
              "assignee": null,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537881000
            },
            {
              "starttime": 1537886400,
              "origin": "2b6f30dd151759cf3",
              "id": "a0b74026b0e1acc31",
              "duration": 50,
              "readonly": false,
              "request_id": "a0b74026b0e1acc31",
              "room": "2b6f30dd151759cf3",
              "day": 1537833600,
              "assignee": null,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537889400
            },
            {
              "starttime": 1537890000,
              "origin": "2b6f30dd151759cf3",
              "id": "599aa7789ceb72910",
              "duration": 50,
              "readonly": false,
              "request_id": "599aa7789ceb72910",
              "room": "2b6f30dd151759cf3",
              "day": 1537833600,
              "assignee": null,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537893000
            },
            {
              "starttime": 1537893600,
              "origin": "2b6f30dd151759cf3",
              "id": "57ce2de524df5b4d5",
              "duration": 40,
              "readonly": false,
              "request_id": "57ce2de524df5b4d5",
              "room": "2b6f30dd151759cf3",
              "day": 1537833600,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537896000
            },
            {
              "starttime": 1537896300,
              "origin": "2b6f30dd151759cf3",
              "id": "1334ed4272c2b34ba",
              "duration": 35,
              "readonly": false,
              "request_id": "1334ed4272c2b34ba",
              "room": "2b6f30dd151759cf3",
              "day": 1537833600,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537898400
            }
          ]
        }
      ]
    },
    {
      "id": "d72deecdc541433f7",
      "name": "Track3",
      "days": [
        {
          "day": 1537920000,
          "slots": [
            {
              "starttime": 1537959900,
              "origin": "d72deecdc541433f7",
              "id": "52522c9149a6ea4b3",
              "duration": 50,
              "readonly": false,
              "request_id": "52522c9149a6ea4b3",
              "talk": {
                "created": 1522439133,
                "notes": "The OpenCI initiative that has been established recently and it is crucial to have participation from Apache Community to solve the challenges in CI\/CD and Infrastructure in a collaborative manner.",
                "description": "Various initiatives have been going on across open source communities to address the challenges in end-to-end integration & testing, especially when there is a need to bring different open source components together to see how well they work in system context.\n\nHowever, working on the problems that are common and span across different communities in an isolated manner is not beneficial for the ecosystem since what is done by each of these communities can potentially be shared by others who are working on solving similar problems. This includes but not limited to improved way of working, alignment on CI\/CD, reuse of the tooling.\n\nRecently, developers from various open source communities such as OpenStack, CNCF, OPNFV, ONAP, OpenDaylight, fd.io, and Ansible came together and started working on things in a collaborative manner. The thinking behind this was that once we get to know each other and start talking, the rest would be much easier and quicker. The topics of interest are infrastructure, CI\/CD, DevOps, integration & testing so we could look for the answers together.\n\nIn this session we will talk about the OpenCI initiative and present our progress to participants and invite Apache Community and wider open source ecosystem take part in it.",
                "tags": "CI, CD, DevOps, Infrastructure",
                "id": "48ff252bc37781573",
                "pending": false,
                "bio": "Fatih Degirmenci\n\nFatih Degirmenci is a Principal Developer at Ericsson Product Development Unit Cloud. He is specialized in automation, CI\/CD, DevOps, and Software Development Infrastructure  and currently involved in several large scale CI\/CD activities across Ericsson. He is a member of the OPNFV Technical Steering Committee and Project Team Lead of OPNFV Release Engineering Project. Before moving to his current role, Fatih worked in WCDMA MS RAN and took active part in CI Transformation, paving the way for Continuous Deployment. Prior to Ericsson, he worked for Havelsan Inc and provided expertise to its customers such as BOEING and BAE Systems.\n\nMelvin Hillsman\n\nI began my OpenStack experience as hobbyist and moved on to be an OpenStack Support Engineer with Rackspace, focused on succeeding technically while providing excellent service and support. Since initially engaging with OpenStack, I became extremely passionate about its success in every market across the globe. In just under two years I succeeded in creating an OpenStack Meetup in Houston, TX, becoming one of the leaders of the Ops Meetups Team, and leading the reboot of the OSOps Project. Additionally I am able to work with community operators, application developers, and end users as a member of the OpenStack User Committee.\n\nI live in the great city of Houston, TX with my awesome family and enjoy spending most of my time learning more about the information and technology field from innovations in microprocessing, changes in DataCenter infrastructure, to the latest trends in Cloud Computing.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "onhold": false,
                "request_id": "48ff252bc37781573",
                "title": "Bringing Open Source Communities Together: OpenCI",
                "speaker": "Fatih Degirmenci, Melvin Hillsman",
                "conference": "apachecon-north-america-2018",
                "submitter": "b2dd43401b55aa0b58a31fc354f56587afe3fa90",
                "level": 0,
                "accepted": true
              },
              "room": "d72deecdc541433f7",
              "day": 1537920000,
              "assignee": "48ff252bc37781573",
              "title": "11:05 -> 11:55 (50 min)",
              "endtime": 1537962900
            },
            {
              "starttime": 1537963500,
              "origin": "d72deecdc541433f7",
              "id": "7824eabdd494bd33b",
              "duration": 50,
              "readonly": false,
              "request_id": "7824eabdd494bd33b",
              "talk": {
                "created": 1522451751,
                "notes": "",
                "description": "Businesses are getting more and more data oriented, enabling them to evolve faster. With evolving businesses, data collected and generated changes too, and so does the schemas of these data. Having to maintain and update schemas for each component individually across data pipelines would not scale for today’s businesses.\n\nIn this talk, Ashish will discuss how Pinterest Data Engineering enabled schema evolution across it’s data pipeline. The talk will cover details on shortcomings of current Apache Hive schema design and ways to support schema evolution in pipelines involving Apache Hive. The talk will also discuss how schema evolution can be achieved even in cases where on-disk file format maintains its own schema for efficiency. This talk will help existing and new Apache Hive users and developers to better understand the possibility of achieving schema evolution in Apache Hive.",
                "tags": "Apache Hive, Apache Thrift, Apache Parquet, Pinterest, Data Engineering",
                "id": "c6a30df123e7fd116",
                "pending": false,
                "bio": "Ashish Singh is a Software Engineer, building platform to process petabytes of data at Pinterest. Prior to Pinterest, Ashish worked as part of ingest team at Cloudera to make data movement easier in large-scale data architectures. Ashish studied Computer Science and Engineering at the Ohio State University. Before working in the Big Data space, he worked on optimizing MPI collective communications on High Performance Computing clusters. Ashish is a committer on Apache Sentry and have contributed to Apache Kafka, Apache Parquet and Apache Hive in past.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "onhold": false,
                "request_id": "c6a30df123e7fd116",
                "title": "Schema Evolution in Apache Hive at Scale",
                "speaker": "Ashish Singh",
                "conference": "apachecon-north-america-2018",
                "submitter": "8fe90b22d927ed6a69e5829a08eb3fa93156ac7a",
                "level": 0,
                "accepted": true
              },
              "room": "d72deecdc541433f7",
              "day": 1537920000,
              "assignee": "c6a30df123e7fd116",
              "title": "12:05 -> 12:55 (50 min)",
              "endtime": 1537966500
            },
            {
              "starttime": 1537972200,
              "origin": "d72deecdc541433f7",
              "id": "6f22b0c981c16487a",
              "duration": 50,
              "readonly": false,
              "request_id": "6f22b0c981c16487a",
              "talk": {
                "created": 1522125414,
                "notes": "Apache (incubating) Quickstep is a new data platform and in this talk we will describe it, and also launch the latest release. ",
                "description": "Modern servers pack enough storage and computing power that just a decade ago was spread across a modest-sized cluster. To exploit the full potential of modern servers, which can be viewed as a data-center-in-a-box, one needs to fundamentally build into the underlying data platform mechanisms for a) unbounded intra and inter-operator parallelism, b) sophisticated query optimization techniques, and c) hybrid storage mechanisms. Apache (incubating) Quickstep is data platform that is built from ground up, and in a principled way, to meet this need. To keep the project focused, the project’s initial target is read-mostly in-memory data warehousing workloads in single-node settings. This talk describes the architecture and design of this initial version of Quickstep.\n\nThis talk will also describe results from a performance evaluation comparing Quickstep to newer systems like Apache Spark and traditional systems like PostgreSQL. Quickstep outperforms these systems by over 10X in most cases.\n\nThis talk will also discuss how the hardware trends point to higher storage and compute densities in individual servers. The natural consequence of this trend is that focusing on the Quickstep approach of “scaling-up” to exploit the full hardware parallelism is critical for the future of high-performance data platforms. This scaling-up approach is complementary to “scaling-out,” which is also on the Quickstep project roadmap, and this talk will also describe the initial plan for a distributed version of Quickstep.",
                "tags": "",
                "id": "bbf9905f9ed509f91",
                "pending": false,
                "bio": "Jignesh Patel is a Professor in Computer Sciences at the University of Wisconsin-Madison. He has published over 100 papers and won several best paper awards. He has a strong interest in seeing research ideas transition to actual products. His Ph.D. thesis work was acquired by NCR\/Teradata in 1997. In 2007 he founded Locomatix, which became part of Twitter in 2013, and seeded the technology that became Heron. Heron now powers all real-time services at Twitter. His last company, Quickstep Tech. was acquired by Pivotal in 2015. He is also the recipient of the Wisconsin COW Teaching Award, and the U. Michigan College of Engineering Education Excellence Award. He is an ACM Fellow, Fellow of the IEEE, and serves on the board of Lands’ End and a number of technology startups.",
                "ttype": "3cf5d8e3f090ee27c2ef29ae8",
                "request_id": "bbf9905f9ed509f91",
                "onhold": false,
                "title": "Apache Quickstep: A high-performance data analytics platform for modern servers",
                "speaker": "Jignesh Patel",
                "conference": "apachecon-north-america-2018",
                "submitter": "3e6933d470e84b0dd2934e19382527d872b13465",
                "level": 0,
                "accepted": true
              },
              "room": "d72deecdc541433f7",
              "day": 1537920000,
              "assignee": "bbf9905f9ed509f91",
              "title": "14:30 -> 15:20 (50 min)",
              "endtime": 1537975200
            },
            {
              "starttime": 1537975800,
              "origin": "d72deecdc541433f7",
              "id": "ee6789881780cd409",
              "duration": 50,
              "readonly": false,
              "request_id": "ee6789881780cd409",
              "talk": {
                "created": 1522417153,
                "notes": "No special requirements but just to note that I've given this talk a few time before at ApaceCon and other conferences. This will be an updated version.",
                "description": "Apache Mynewt is an operating system for low powered embedded systems based on 32-bit microcontrollers. At the core is a small pre-emptive RTOS and an extensive set of modules for connectivity, file systems, power and performance management options and lots more. It is a highly flexible, responsive, general purpose OS for constrained devices, think of it as embedded Linux for devices that can’t run Linux. Features include a secure bootloader, image management, hardware abstraction, instrumentation for stats and logs. This makes it easy to going from prototype to production when using Apache Mynewt without having to reinvent the wheel.",
                "tags": "IoT",
                "id": "5a6dca1282f4d969f",
                "pending": false,
                "bio": "Justin Mclean has more than 25 years’ experience in developing web-based applications and is heavily involved in open source hardware and software. He runs his own consulting company Class Software and has spoken at numerous conferences in Australia and overseas.\n\nIn his free time, he's active in several Apache Software Foundation projects, including the Apache Incubator, Apache Mynewt and Apache PLC4X and is a mentor for a number of their projects. He's also runs various courses, is a co-author of a book on Android development, a casual academic at the University of NSW in a course on computational design, teaches school children about robotics, electronics and 3d printing and runs the IoT meetup in Sydney.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "5a6dca1282f4d969f",
                "onhold": false,
                "title": " Apache Mynewt - ASFs First Embedded OS Project",
                "speaker": "Justin Mclean",
                "conference": "apachecon-north-america-2018",
                "submitter": "7db3cfb4891f498aa63b62ff72002cfaafc9ad5a",
                "level": 1,
                "accepted": true
              },
              "room": "d72deecdc541433f7",
              "day": 1537920000,
              "assignee": "5a6dca1282f4d969f",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537978800
            },
            {
              "starttime": 1537980000,
              "origin": "d72deecdc541433f7",
              "id": "bd3524cc715ddc499",
              "duration": 50,
              "readonly": false,
              "request_id": "bd3524cc715ddc499",
              "talk": {
                "created": 1522370158,
                "notes": "",
                "description": "Day by day, the number of open source projects continues to increase. Each project has unique communities and practice different development methodologies. This talk will focus on the Apache Mesos, Kubernetes and Cloud Foundry cultures and outline their main differences and commonalities. The projects have different review processes from the pair programming model to the LGTM process, an interesting artifact of github. Becoming a committer on CF relies on the Dojo, while Mesos & Kubernetes depend on individual sponsors.\n\nThe session will cover contributors' journeys & perspectives on their respective open source experiences. By sharing insight into these communities, people will have the tools and knowledge necessary to start\/increase their participation to open source development.",
                "tags": "Community,Governance",
                "id": "57568434112033acd",
                "pending": false,
                "bio": "After contributing to Docker & Kubernetes for the last 2 years, Morgan has gained valuable insight into the varying culture around open source container technology. Morgan is a maintainer on the core Docker Engine and also a founding contributor of the Kubernetes Service-Catalog.\n\nSrinivas Brahmaroutu works as a Software Engineer at IBM Corp. He has many years of experience around IBM cloud offerings. He has worked on many strategic open source projects including Cloud Foundry, Docker and Mesos. Currently he works on Kubernetes contributing to test-infra and conformance.\n\nSwetha Repakula has been working in IBM’s Open Technologies division for the last two and half years. Since November 2017, she has been working on the Hyperledger Fabric, an open source Blockchain platform, specifically the EVM integration. Previously she was a full time open source contributor for Cloud Foundry. Working as a CF commiter, she had the opportunity to directly work with engineers from different companies and witness how corporations can come together and effectively cooperate to contribute to open source technology.\n\n",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "57568434112033acd",
                "onhold": false,
                "title": "Comparisons of Cloud Native Communities",
                "speaker": "Morgan Bauer, Srinivas Brahmaroutu, Swetha Repakula",
                "conference": "apachecon-north-america-2018",
                "submitter": "a10574eee4dc4d7281b9f8aa1ffdbb99c8b0b7f1",
                "level": 0,
                "accepted": true
              },
              "room": "d72deecdc541433f7",
              "day": 1537920000,
              "assignee": "57568434112033acd",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537983000
            }
          ]
        },
        {
          "day": 1538092800,
          "slots": [
            {
              "starttime": 1538125200,
              "origin": "d72deecdc541433f7",
              "id": "cc51d154f6c6b6f44",
              "duration": 50,
              "readonly": false,
              "request_id": "cc51d154f6c6b6f44",
              "talk": {
                "created": 1521162441,
                "notes": "An updated version of my introductory and interactive talk from ApacheCon Miami.  This focuses specifically on the behaviors in the Apache Way, in a practical way anyone can use.",
                "description": "The Apache Way is a set of behaviors and techniques that anyone - organizations and individuals alike - can use to be more effective at working in distributed communities.  Open source does not necessarily mean open development - and true community-led open development \nis where the fun starts when working in FOSS!\n\nThis is an interactive review of the core behaviors used by Apache projects to help them stay healthy and productive over the long term.  While these behaviors are often required at the ASF, they are valuable to any collaborative project where the contributors are distributed across companies, continents, and experiences.\n\nAttendees will leave with a clear understanding of practical actions they can take to help improve their own open source experience, and how to help their communities succeed together.\n\nThe behaviors you need to succeed at Apache.",
                "tags": "apache, community, governance",
                "id": "0beb0673a0323ccc9",
                "pending": false,
                "bio": "Shane is the founder of Punderthings℠ LLC consultancy, helping organizations find better ways to engage with the critical open source projects that power modern technology and business.  He blogs and tweets about open source governance and trademark issues, and has spoken at major technology conferences like ApacheCon, OSCON, All Things Open, Community Leadership Summit, and Ignite. \n\nShane is serving a seventh term as an elected Director of the ASF, providing governance oversight, community mentoring, and fiscal review for all Apache projects.  Previously, he served eight years as Vice President of Brand Management for the Apache Software Foundation (ASF), a Delaware 501C3 non-profit public charity.  He wrote the trademark and branding policies that cover all 200+ Apache® projects, including assisting projects with defining and policing their trademarks, as well as negotiating agreements with various software vendors using Apache software brands.  \n\n Otherwise, Shane is: a father and husband, a BMW driver, and punny guy. Oh, and we have cats. Follow @ShaneCurcuru and read http:\/\/CommunityOverCode.com and http:\/\/ChooseAFoundation.com",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "0beb0673a0323ccc9",
                "onhold": false,
                "title": "The Apache Way - Effective Open Source Project Management ",
                "speaker": "Shane Curcuru",
                "conference": "apachecon-north-america-2018",
                "submitter": "cd70f42af37db22835e8e9cc7fc7fec8eee09333",
                "level": 0,
                "accepted": true
              },
              "room": "d72deecdc541433f7",
              "day": 1538092800,
              "assignee": "0beb0673a0323ccc9",
              "title": "09:00 -> 09:50 (50 min)",
              "endtime": 1538128200
            },
            {
              "starttime": 1538128800,
              "origin": "d72deecdc541433f7",
              "id": "c7674f67278f2a866",
              "duration": 50,
              "readonly": false,
              "request_id": "c7674f67278f2a866",
              "talk": {
                "created": 1521744367,
                "notes": "This talk is the outcome of years of work. All is not yet shared on Dzone and it has no special requirements.\n\n \n1) https:\/\/dzone.com\/articles\/using-your-favorite-dynamic-language-with-apache-s",
                "description": "In this talk, you will see how through integration, the charitable Apache Software Foundation with its great open source projects, has helped us to build an unbeatable foundation for our products and services to develop the Senegalese IT ecosystem at a lower cost. We will cover in depth why and how in an non-intrusive way, we have transformed the Apache Struts framework to make it much easier to use, much faster, much lightweight, modular, multi-template, microservices oriented and highly scalable with an integration with the Apache Groovy language. We will end this talk by the presentation of our customer portal, the first progressive Java web application made with no entity by the magic of the groovy.json, groovy.sql packages and the Expando class, and moreover when Apache POI meets MS Word to auto-generate the legal contract which links a customer to our company ThinkTech and  which is next uploaded and hosted on the file hosting service, Dropbox.",
                "tags": "Struts, Groovy, MicroServices, PWA, APIS, CORS",
                "id": "546bd6e19034f5149",
                "pending": false,
                "bio": "Mamadou Lamine Ba is a Software Developer, Architect and the CEO of ThinkTech. He enjoys reading, writing and of course building innovative solutions on top of cutting-edge technologies. You can reach him at lamine.ba@thinktech.sn",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "onhold": false,
                "request_id": "546bd6e19034f5149",
                "title": "Apache : Our Unbeatable Foundation",
                "speaker": "Mamadou Lamine Ba",
                "conference": "apachecon-north-america-2018",
                "submitter": "b625960e3dbd8eb79adb5f870cd6b1c74ef46ccb",
                "level": 2,
                "accepted": true
              },
              "room": "d72deecdc541433f7",
              "day": 1538092800,
              "assignee": "546bd6e19034f5149",
              "title": "10:00 -> 10:50 (50 min)",
              "endtime": 1538131800
            },
            {
              "starttime": 1538133600,
              "origin": "d72deecdc541433f7",
              "id": "2c44967b0c20acb58",
              "duration": 50,
              "readonly": false,
              "request_id": "2c44967b0c20acb58",
              "talk": {
                "created": 1517329776,
                "notes": "Can be a keynote or general speech.  I think a keynote and the tie in with the meritocracy might be excellent given the age of Harvey Weinstein we've had.  Will defer to Shane if he wants to give the speech.",
                "description": "Based on the posting at https:\/\/blogs.apache.org\/foundation\/entry\/success-at-apache-meritocracy, this talk introduces attendees to some of the key points of the Apache Way especially focusing on meritocracy and how we encourage inclusion while simultaneously being elitist. \n\nWill cover the Apache Way Tenants:\n\nCharity (FOSS)\nCommunity (Community over Code)\nConsensus (Consensus versus Voting)\nMeritocracy (JFDI)\nTransparency (If it didn't happen on list...)\nPragmatic (GPL vs ASLv2 - https:\/\/www.linkedin.com\/pulse\/conundrucrats-assemble-kevin-a-mcgrail\/)\n",
                "tags": "",
                "id": "6e38e1045b72595bf",
                "pending": false,
                "bio": "Kevin A. McGrail \nMember, Asst. Treasurer, VP Fundraising & Apache SpamAssassin Chair Emeritus \nApache Software Foundation\nCEO, PCCC.com\n\nKevin A. McGrail, aka KAM, has been helping the Apache SpamAssassin project for longer than he would like to admit.  He also serves as an assistant treasurer and VP Fundraising for the Apache Software Foundation. \n\nHe prides himself a cyber security and privacy expert with his work being used in numerous commercial platforms. \n\nKevin is a proud start-up entrepreneur who founded his first company at 21 and is a MACH37 F15 Graduate. He is also an advisor for SecurityUniversity.edu & Virtru.com.\n\nhttps:\/\/www.linkedin.com\/in\/kmcgrail",
                "ttype": "3cf5d8e3f090ee27c2ef29ae8",
                "request_id": "6e38e1045b72595bf",
                "onhold": false,
                "title": "Inclusion, Meritocracy and the Apache Way",
                "speaker": "Kevin A. McGrail",
                "conference": "apachecon-north-america-2018",
                "submitter": "5cbc55d4962009d16b2ae1ef04a21d8fd8a3e609",
                "level": 0,
                "accepted": true
              },
              "room": "d72deecdc541433f7",
              "day": 1538092800,
              "assignee": "6e38e1045b72595bf",
              "title": "11:20 -> 12:10 (50 min)",
              "endtime": 1538136600
            },
            {
              "starttime": 1538137200,
              "origin": "d72deecdc541433f7",
              "id": "c941020d516b57f61",
              "duration": 50,
              "readonly": false,
              "request_id": "c941020d516b57f61",
              "talk": {
                "created": 1521161878,
                "notes": "Thanks!",
                "description": "Open source sustainability is more than just individuals figuring out how to make a living off of open source. Have you ever wondered who actually pays for open source? Not just developers, but the whole ecosystem around major open source projects, either at a FOSS Foundation, independent or an open core project at a company?\n\nThe major software projects we all rely on are mostly hosted at Foundations like Apache, Eclipse, Linux, or Software Freedom Conservancy.  Those foundations provide a wide variety of support to project communities, including legal and licensing assistance, trademark management, event support, and more. As non-profits, these foundations rely on donors and sponsors for all of their work.\n\nSo who pays for all of this critical support for open source foundations? Come find out what companies are behind the popular open source foundations and major independent projects, and who's actually paying for all of the other support work that's done to keep the servers running, press releases coming, and license compliance work.\n\nSurprises are guaranteed; I know I was surprised when I realized how many different FOSS projects that Microsoft is an annual sponsor for, and what projects a few other companies supported with their cash.",
                "tags": "sustainability, funding, sponsors",
                "id": "f428ea1c164a29361",
                "pending": false,
                "bio": "Shane is the founder of Punderthings℠ LLC consultancy, helping organizations find better ways to engage with the critical open source projects that power modern technology and business.  He blogs and tweets about open source governance and trademark issues, and has spoken at major technology conferences like ApacheCon, OSCON, All Things Open, Community Leadership Summit, and Ignite. \n\nShane is serving a seventh term as an elected Director of the ASF, providing governance oversight, community mentoring, and fiscal review for all Apache projects.  Previously, he served eight years as Vice President of Brand Management for the Apache Software Foundation (ASF), a Delaware 501C3 non-profit public charity.  He wrote the trademark and branding policies that cover all 200+ Apache® projects, including assisting projects with defining and policing their trademarks, as well as negotiating agreements with various software vendors using Apache software brands.   \n\nOtherwise, Shane is: a father and husband, a BMW driver, and punny guy. Oh, and we have cats. Follow @ShaneCurcuru and read http:\/\/CommunityOverCode.com and http:\/\/ChooseAFoundation.com",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "f428ea1c164a29361",
                "onhold": false,
                "title": "Who Pays For Open Source?",
                "speaker": "Shane Curcuru",
                "conference": "apachecon-north-america-2018",
                "submitter": "cd70f42af37db22835e8e9cc7fc7fec8eee09333",
                "level": 0,
                "accepted": true
              },
              "room": "d72deecdc541433f7",
              "day": 1538092800,
              "assignee": "f428ea1c164a29361",
              "title": "12:20 -> 13:10 (50 min)",
              "endtime": 1538140200
            },
            {
              "starttime": 1538145600,
              "origin": "d72deecdc541433f7",
              "id": "46a90ec47bc3bb3fd",
              "duration": 50,
              "readonly": false,
              "request_id": "46a90ec47bc3bb3fd",
              "talk": {
                "created": 1522162748,
                "notes": "",
                "description": "Communicating in written form is hard anyway, and our Open Source circles add the additional hurdle of different cultural backgrounds and sensitivities.\n\nIrony doesn't work. Jokes don't work. People get offended for no reason. They don't get what you're saying. Or they get it all wrong. Misunderstandings and conflicts are just around the corner, although we think we do our best to be efficient, fun and entertaining when talking to our project communities.\n\nThe problem is that our cultural backgrounds get in the way and shape the way we perceive many of the subtle nuances of human communication. Puzzled (or horrified) faces can help steer face-to-face conversations the right way, but we don't have this luxury in the asynchronous written communications which are the norm in Open Development.\n\nThis talk will describe a number of areas and communication patterns where we need to be extra careful in multi-cultural environments.\n\nBased on 17 years of experience in many projects of the Apache Software Foundation, our concrete examples of fun anecdotes, unnerving communication mishaps and nuclear-level conflicts (almost) will help us avoid common pitfalls and have happier and more efficient conversations in multi-cultural environments.",
                "tags": "community,collaboration",
                "id": "ba78a393425e43f2f",
                "pending": false,
                "bio": "Bertrand Delacretaz (http:\/\/grep.codeconsult.ch\/) works as a Principal Scientist with the Adobe Research team in Basel, Switzerland. He spends a good portion of his time advocating and implementing Open Development as a way to make geographically dispersed teams more efficient and more fun for his coworkers. Bertrand is also an active Member of the Apache Software Foundation, currently (2018-2019) on his tenth term on the Foundation's Board of Directors.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "ba78a393425e43f2f",
                "onhold": false,
                "title": "They don't understand me! - tales from the multi-cultural trenches",
                "speaker": "Bertrand Delacretaz",
                "conference": "apachecon-north-america-2018",
                "submitter": "ae0028a2be6d407d35810433e1812e89a6882810",
                "level": 0,
                "accepted": true
              },
              "room": "d72deecdc541433f7",
              "day": 1538092800,
              "assignee": "ba78a393425e43f2f",
              "title": "14:40 -> 15:30 (50 min)",
              "endtime": 1538148600
            },
            {
              "starttime": 1538149200,
              "origin": "d72deecdc541433f7",
              "id": "781be391513275c9a",
              "duration": 50,
              "readonly": false,
              "request_id": "781be391513275c9a",
              "talk": {
                "created": 1521755196,
                "notes": "",
                "description": "\"If it didn't happen on the list, it didn't happen\" is a common mantra around Apache projects. It means that no decision about an Apache project can happen outside of the community. Every decision must be consented to by the whole project community. But companies, who often pay the wages of community members, have secrets. They will undoubtedly want Apache projects to go in specific directions to benefit their own strategy. How do we manage these conflicting goals. \n\nSurprisingly, in a typical Apache project it isn't all that hard, though it does require a certain skill in translating internal strategies to Apache deliverables that will gain the support of the community. This talk will look at some of the strategies employed both inside the company and inside the community to bring alignment and avoid conflict.",
                "tags": "community, best practice, apache way",
                "id": "0054bda6dcde0cd35",
                "pending": false,
                "bio": "Ross Gardler has been around Apache since the late '90s. Much of this time was spent as an independent consultant. For the last 5 years he's worked at Microsoft as a Program Manager where he works on a number of Linux and open source initiatives on Azure. Ross' focus has always been on the importance of community to a successful open source project, where success for him is defined by the market. This leads to attempt to constantly learn and improve a matching of commercial business objectives with collaborative development models. Ross continues to believe that the Apache Way is the easiest way to align these often competing views.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "0054bda6dcde0cd35",
                "onhold": false,
                "title": "Balancing Transparency and Secrecy",
                "speaker": "Ross Gardler",
                "conference": "apachecon-north-america-2018",
                "submitter": "e7d4f31d7edc1273da57c139cfbe3e38f92e0230",
                "level": 0,
                "accepted": true
              },
              "room": "d72deecdc541433f7",
              "day": 1538092800,
              "assignee": "0054bda6dcde0cd35",
              "title": "15:40 -> 16:30 (50 min)",
              "endtime": 1538152200
            },
            {
              "starttime": 1538152800,
              "origin": "d72deecdc541433f7",
              "id": "647aa0ea081b58ecb",
              "duration": 50,
              "readonly": false,
              "request_id": "647aa0ea081b58ecb",
              "talk": {
                "created": 1519063050,
                "notes": "",
                "description": "The success of Open Source has resulted in companies now levering, consuming and contributing to Open Source projects. But another, even more influential aspect of the Open Source movement is moving into the Enterprise, that of using the \"lessons learned\" of successful software development and management and bringing those methodologies in-house. The Apache Way serves as the prime example of successful s\/w development and is the core foundation of the InnerSource movement.",
                "tags": "software development, inner source, enterprise development",
                "id": "e36b627904e32b7d7",
                "pending": false,
                "bio": "Jim Jagielski is a well known and acknowledged expert and visionary in Open Source, an accomplished coder, and frequent engaging presenter on all things Open, Web and Cloud related. As a developer, he’s made substantial code contributions to just about every core technology behind the Internet and Web and in 2012 was awarded the O’Reilly Open Source Award and in 2015 received the Innovation Luminary Award from the EU. He is likely best known as one of the developers and co-founders of the Apache Software Foundation, where he has previously served as both Chairman and President and where he’s been on the Board Of Directors since day one. Currently he is Vice-Chairman. He’s served as President of the Outercurve Foundation and was also a director of the Open Source Initiative (OSI). Up until recently, he worked at Capital One as a Sr. Director in the Tech Fellows program. He credits his wife Eileen in keeping him sane.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "e36b627904e32b7d7",
                "onhold": false,
                "title": "The Apache Way and InnerSource",
                "speaker": "Jim Jagielski",
                "conference": "apachecon-north-america-2018",
                "submitter": "48337cfe5eda963e4ac084b5e3c663a3e143926a",
                "level": 1,
                "accepted": true
              },
              "room": "d72deecdc541433f7",
              "day": 1538092800,
              "assignee": "e36b627904e32b7d7",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1538155800
            }
          ]
        },
        {
          "day": 1537833600,
          "slots": [
            {
              "starttime": 1537866000,
              "origin": "d72deecdc541433f7",
              "id": "0535283f8f8ff1156",
              "duration": 50,
              "readonly": false,
              "request_id": "0535283f8f8ff1156",
              "room": "d72deecdc541433f7",
              "day": 1537833600,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537869000
            },
            {
              "starttime": 1537869600,
              "origin": "d72deecdc541433f7",
              "id": "b1a74a1ff4b8028bc",
              "duration": 50,
              "readonly": false,
              "request_id": "b1a74a1ff4b8028bc",
              "room": "d72deecdc541433f7",
              "day": 1537833600,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537872600
            },
            {
              "starttime": 1537874400,
              "origin": "d72deecdc541433f7",
              "id": "5e73561ba0f451c12",
              "duration": 50,
              "readonly": false,
              "request_id": "5e73561ba0f451c12",
              "room": "d72deecdc541433f7",
              "day": 1537833600,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537877400
            },
            {
              "starttime": 1537878000,
              "origin": "d72deecdc541433f7",
              "id": "4e97cfe917aedb891",
              "duration": 50,
              "readonly": false,
              "request_id": "4e97cfe917aedb891",
              "room": "d72deecdc541433f7",
              "day": 1537833600,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537881000
            },
            {
              "starttime": 1537886400,
              "origin": "d72deecdc541433f7",
              "id": "ad27be06584340d42",
              "duration": 50,
              "readonly": false,
              "request_id": "ad27be06584340d42",
              "room": "d72deecdc541433f7",
              "day": 1537833600,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537889400
            },
            {
              "starttime": 1537890000,
              "origin": "d72deecdc541433f7",
              "id": "b6950cb6cfb444d92",
              "duration": 50,
              "readonly": false,
              "request_id": "b6950cb6cfb444d92",
              "room": "d72deecdc541433f7",
              "day": 1537833600,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537893000
            },
            {
              "starttime": 1537896300,
              "origin": "d72deecdc541433f7",
              "id": "5cc4495b5b02b62a6",
              "duration": 35,
              "readonly": false,
              "request_id": "5cc4495b5b02b62a6",
              "room": "d72deecdc541433f7",
              "day": 1537833600,
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1537898400
            }
          ]
        },
        {
          "day": 1538006400,
          "slots": [
            {
              "starttime": 1538043300,
              "origin": "d72deecdc541433f7",
              "id": "29b255ee0bb391369",
              "duration": 50,
              "readonly": false,
              "request_id": "29b255ee0bb391369",
              "talk": {
                "created": 1520457432,
                "notes": "None",
                "description": "At Yelp, we use distributed cloud computation on top of Apache Mesos and AWS to improve performance and achieve efficient resource utilization; everything from unit and integration tests to the production services powering Yelp.com run on such clusters. Each of these clusters is powered by machines running in the cloud, and have different workloads and resource requirements. In order to ensure that we have sufficient capacity for running jobs, while also keeping costs down during periods of low usage, cluster-wide autoscaling is necessary. This talk will describe:\n\n* Our open-source cluster autoscaling tool for Apache Mesos, called ClusterMan\n* How we built a simulation environment for ClusterMan to test changes before they go live\n* How the simulator helped us understand recent changes to the pricing model for cloud computation\n* How ClusterMan's autoscaling has saved ~50% on our distributed clusters, while still ensuring sufficient compute capacity for tasks\n* How we are using the simulator and machine learning models to build predictive autoscaling signals",
                "tags": "mesos, autoscaling, simulation",
                "id": "a6c0daeb1b9af4f3b",
                "pending": false,
                "bio": "David R. Morrison, PhD; Software Engineer @Yelp\ndrmorr@yelp.com \nhttp:\/\/evokewonder.com\/research\n\nDavid R. Morrison is a software engineer working in scheduling and optimization on the Distributed Systems team at Yelp, where he has developed auto-scaling code for Yelp's most expensive compute clusters. Previously, David worked in research and development at Inverse Limit, where he received federal funding from DARPA and Google's ATAP program. David has contributed code to a number of open-source projects, including qemu, botocore, moto, and others. David received his PhD in computer science from the University of Illinois, Urbana-Champaign under the supervision of Dr. Sheldon Jacobson. David has spoken at the INFORMS Business Analytics conference in 2017, at AWS re:Invent 2016, at the International Symposium on Mathematical Programming 2015, and multiple other venues.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "a6c0daeb1b9af4f3b",
                "onhold": false,
                "title": "Predictive Autoscaling for Apache Mesos",
                "speaker": "David R. Morrison",
                "conference": "apachecon-north-america-2018",
                "submitter": "9007c6e0434d7bdbe60abdebe7c63842396f5f7a",
                "level": 1,
                "accepted": true
              },
              "room": "d72deecdc541433f7",
              "day": 1538006400,
              "assignee": "a6c0daeb1b9af4f3b",
              "title": "10:15 -> 11:05 (50 min)",
              "endtime": 1538046300
            },
            {
              "starttime": 1538046900,
              "origin": "d72deecdc541433f7",
              "id": "6f5f0d7b2d7555638",
              "duration": 50,
              "readonly": false,
              "request_id": "6f5f0d7b2d7555638",
              "talk": {
                "created": 1522412292,
                "notes": "",
                "description": "This talk explains why graph database, Apache S2Graph, is a great choice to build online advertising system, especially data management platform and audience targeting. Kakao operates the third largest advertising system in South Korea, and Apache S2Graph has been powered audience targeting and data management platform for a year. This talk will go through from collecting user activities, processing it, then how to storing\/querying data in graph database for audience targeting. Also integration with external system, Druid will be shared to explain how data management platform find out the number of audience with targeting condition. People who is interested in advertising system, especially audience targeting can benefit from this talk.",
                "tags": "Graph Database",
                "id": "835a6adcab1ce83a0",
                "pending": false,
                "bio": "Doyung leads a data infrastructure team at Kakao, where his focus is on performance and usability. He developed Apache S2Graph, an open-source distributed graph database, and has previously presented it at ApacheCon BigData Europe and ApacheCon BigData North America.\t",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "onhold": false,
                "request_id": "835a6adcab1ce83a0",
                "title": "Build data management platform and audience targeting for online advertising system using Graph Database, Apache S2Graph(incubating).",
                "speaker": "Doyung Yoon",
                "conference": "apachecon-north-america-2018",
                "submitter": "2fdf5080804c17d8e73596a70302f7de67488707",
                "level": 1,
                "accepted": true
              },
              "room": "d72deecdc541433f7",
              "day": 1538006400,
              "assignee": "835a6adcab1ce83a0",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1538049900
            },
            {
              "starttime": 1538050500,
              "origin": "d72deecdc541433f7",
              "id": "8c79b289ae24b80df",
              "duration": 50,
              "readonly": false,
              "request_id": "8c79b289ae24b80df",
              "talk": {
                "created": 1519514129,
                "notes": "",
                "description": "Apache Solr is a search engine. It is built on top of Lucene library, but also leverages many other Apache projects (Tika, OpenNLP, Velocity, Zookeeper). In its own turn, Solr is integrated by other Apache project (Nutch, Zeppelin, Camel, NiFi, etc). Understanding where and how those projects connect with Solr allows to benefit from rich features not explicitly described in the Solr's own documentation.\n\nThis talk will do a quick introduction to Solr for the beginners and then go through several concrete examples showcasing Solr use of and Solr use by sister Apache project. Some non-Apache power-libraries will also be highlighted (e.g. ICU4J).\n\nPeople should attend if they have or plan to have search as part of their implementation stack and do not want to reinvent the wheel when facing complex issues.",
                "tags": "search",
                "id": "91ea04aed8408c8e2",
                "pending": false,
                "bio": "Alexandre Rafalovitch is a full-stack IT specialist with more than 20 years of industry and non-profit experience, including in Java, C# and HTML\/CSS\/JavaScript. He develops projects on Windows, Mac and Linux. Alexandre is an Apache Lucene\/Solr committer since August 2016 and chooses to focus on Solr onboarding experience. Alexandre has written one book about Solr already (Apache Solr for Indexing Data How-to). He has presented at Lucene\/Solr Revolution 2014, 2015, and 2016, as well as multiple times at JavaOne and various smaller venues.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "91ea04aed8408c8e2",
                "onhold": false,
                "title": "Apache Solr: leveraging Apache ecosystem",
                "speaker": "Alexandre Rafalovitch",
                "conference": "apachecon-north-america-2018",
                "submitter": "4558f10e51f40480e2c1aa4ff63e2db95d6cbc29",
                "level": 0,
                "accepted": true
              },
              "room": "d72deecdc541433f7",
              "day": 1538006400,
              "assignee": "91ea04aed8408c8e2",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1538053500
            },
            {
              "starttime": 1538058600,
              "origin": "d72deecdc541433f7",
              "id": "cbeaf7f177e58dbec",
              "duration": 50,
              "readonly": false,
              "request_id": "cbeaf7f177e58dbec",
              "talk": {
                "created": 1522374240,
                "notes": "",
                "description": "Pub-sub messaging systems like Apache Pulsar are being used for an increasingly broad array of data ingestion tasks. Traditionally, these systems have offered at-least-once delivery semantics, leaving the task of implementing idempotent processing to the users.\nThis talk will present a rationale for adding “effectively-once” semantics to Pulsar, which was achieved by adding a message de-duplication layer that can ensure those stricter semantics  with guaranteed accuracy and no performance penalty.\n\nApache Pulsar is a distributed pub\/sub messaging system that originated at Yahoo, where it has been powering many critical systems and user-facing products for several years.\n\nThe traditional API for Pulsar is derived from basic pub\/sub concepts, such as “subscriptions” and “consumers” that receive messages and “acknowledge” their processing. This model is very simple and yet powerful in that it allows you to build applications without needing to understand the underlying intricacies of the messaging system. The only drawback is that previous pub\/sub system offer only “at-least-once” semantics, leaving the task of eliminating duplicated messages to the application. \n\nSince the emergence of stream processing and more demanding requirements, messaging systems need to offer correct primitives to allow implementing “effectively-once” semantics end-to-end, in both the messaging layer and in the processing layer. Here, we use the term “effectively-once” to clarify that messages can actually be replayed multiple times in the presence of failure, though the effects of their processing will be equivalent to exactly once.\n\nThis talk will present the new APIs introduced in Pulsar to offer “effectively-once” semantics and will cover implementation details and performance testing results and provide examples of use cases that can greatly benefit from this new feature.\n",
                "tags": "",
                "id": "a09bfe4b2f545e2f9",
                "pending": false,
                "bio": "Matteo Merli is a software engineer at Streamlio working on messaging and storage technologies. Prior to Streamlio, he spent several years at Yahoo building database replication systems and multi-tenant messaging platforms. He is the co-creator of Apache Pulsar and a member of the PMC of Apache BookKeeper.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "a09bfe4b2f545e2f9",
                "onhold": false,
                "title": "Effectively-once Messaging with Apache Pulsar",
                "speaker": "Matteo Merli",
                "conference": "apachecon-north-america-2018",
                "submitter": "9bd65e25566167609900fb2ab5fba98a6cbfc6b2",
                "level": 0,
                "accepted": true
              },
              "room": "d72deecdc541433f7",
              "day": 1538006400,
              "assignee": "a09bfe4b2f545e2f9",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1538061600
            },
            {
              "starttime": 1538062200,
              "origin": "d72deecdc541433f7",
              "id": "fbeb89fe3320c4327",
              "duration": 50,
              "readonly": false,
              "request_id": "fbeb89fe3320c4327",
              "talk": {
                "created": 1519515118,
                "notes": "",
                "description": "While fully nuanced search implementation takes time, getting basic data ingestion, schema design and critical-path insights does not have to be a painful experience.\n\nIn this talk, we will use several real-life datasets (from \"Data is Plural\" mailing list) and show \"Rapid Application Development\"-style workflow to get the data into Solr and shape it ready for initial searchability and relevancy analysis. \n\nDifferent stages of content ingestion, pre-processing, analysis, and querying will be explained, together with trade-offs of different built-in approaches.\n\nThis talk is for everybody who wanted Search in their development stack but is not sure exactly where to start.",
                "tags": "search",
                "id": "7235c1f684eaa9567",
                "pending": false,
                "bio": "Alexandre Rafalovitch is a full-stack IT specialist with more than 20 years of industry and non-profit experience, including in Java, C# and HTML\/CSS\/JavaScript. He develops projects on Windows, Mac and Linux. Alexandre is an Apache Lucene\/Solr committer since August 2016 and chooses to focus on Solr onboarding experience. Alexandre has written one book about Solr already (Apache Solr for Indexing Data How-to). He has presented at Lucene\/Solr Revolution 2014, 2015, and 2016, as well as multiple times at JavaOne and various smaller venues.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "7235c1f684eaa9567",
                "onhold": false,
                "title": "From content to search: speed-dating Apache Solr",
                "speaker": "Alexandre Rafalovitch",
                "conference": "apachecon-north-america-2018",
                "submitter": "4558f10e51f40480e2c1aa4ff63e2db95d6cbc29",
                "level": 0,
                "accepted": true
              },
              "room": "d72deecdc541433f7",
              "day": 1538006400,
              "assignee": "7235c1f684eaa9567",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1538065200
            },
            {
              "starttime": 1538065800,
              "origin": "d72deecdc541433f7",
              "id": "acc873171544cc4be",
              "duration": 50,
              "readonly": false,
              "request_id": "acc873171544cc4be",
              "talk": {
                "created": 1522115606,
                "notes": "",
                "description": "Apache Dubb (incubating) is one of the newest incubating projects at the Apache Software Foundation.\n\nApache Dubbo(incubating) is a high-performance, java based, open source RPC framework. In addition to interface-based high-performance remote communication capabilities, Dubbo highlights some features especially useful for microservices, which include service discovery, routing, load balance, fault tolerance, etc.\n\nIn this presentation, we will give a brief introduction on the core features  Dubbo provides and the scenarios it applies, demonstrate how to use dubbo to easily drive your project with hands-on examples; We also expect to dive a little bit into Dubbo's design principles, analyze the challenges it faces, and the roadmap to address those challenges after we entered apache community.",
                "tags": "RPC, Dubbo, Distributed System, Microservices",
                "id": "b8db9dc580d85853f",
                "pending": false,
                "bio": "Ian Luo, Staff Engineer at Alibaba. Committer of Apache Dubbo (Incubating). Very rich experience in develop and design fundamental products supporting large-scale distributed systems, e.g., RPC, Application Container and Monitor tools.",
                "ttype": "b6626d3814f174e0dd2e0d407",
                "request_id": "b8db9dc580d85853f",
                "onhold": false,
                "title": "Introducing Apache Dubbo(Incubating): What is Dubbo and How it Works",
                "speaker": "Ian Luo, Jun Liu",
                "conference": "apachecon-north-america-2018",
                "submitter": "2323bee5aa018c09afd56421064baeb35e00f0bd",
                "level": 0,
                "accepted": true
              },
              "room": "d72deecdc541433f7",
              "day": 1538006400,
              "assignee": "b8db9dc580d85853f",
              "title": "16:40 -> 17:30 (50 min)",
              "endtime": 1538068800
            }
          ]
        }
      ]
    }
  ]
}